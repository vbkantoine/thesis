
@article{baillie_variational_2025,
	title = {Variational inference for approximate reference priors using neural networks},
	doi = {10.48550/arXiv.2502.02364},
	journaltitle = {{arXiv}.2502.02364},
	author = {Baillie, Nils and Van Biesbroeck, Antoine and Gauchy, Clément},
	date = {2025},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/7Y3EPRGH/Baillie et al. - 2025 - Variational inference for approximate reference priors using neural networks.pdf:application/pdf},
}

@misc{ambraseys_dissemination_2000,
	title = {Dissemination of European {StrongMotion} Data},
	author = {Ambraseys, Nicholas N. and Smit, Patrick and Berardi, Raniero and Rinaldis, Dario and Cotton, Fabrice and Berge, Catherine},
	date = {2000},
	note = {{CD}-{ROM} collection. European Commission, Directorate-General {XII}, Environmental and Climate Programme, {ENV}4-{CT}97-0397, Brussels, Belgium},
	annotation = {{CD}-{ROM} collection. European Commission, Directorate-General {XII}, Environmental and Climate Programme, {ENV}4-{CT}97-0397, Brussels, Belgium},
}

@report{minka_estimating_2012,
	title = {Estimating a Dirichlet distribution},
	url = {https://www.microsoft.com/en-us/research/publication/estimating-dirichlet-distribution/},
	institution = {Microsoft Research},
	author = {Minka, Thomas},
	date = {2012-01},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/4ZE78JHC/Minka - 2012 - Estimating a Dirichlet distribution.pdf:application/pdf},
}

@inproceedings{huang_neural_2018,
	title = {Neural Autoregressive Flows},
	volume = {80},
	url = {https://proceedings.mlr.press/v80/huang18d.html},
	series = {Proceedings of Machine Learning Research},
	abstract = {Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows ({MAF}) (Papamakarios et al., 2017), and to accelerate state-of-the-art {WaveNet}-based speech synthesis to 20x faster than real-time (Oord et al., 2017), via Inverse Autoregressive Flows ({IAF}) (Kingma et al., 2016). We unify and generalize these approaches, replacing the (conditionally) affine univariate transformations of {MAF}/{IAF} with a more general class of invertible univariate transformations expressed as monotonic neural networks. We demonstrate that the proposed neural autoregressive flows ({NAF}) are universal approximators for continuous probability distributions, and their greater expressivity allows them to better capture multimodal target distributions. Experimentally, {NAF} yields state-of-the-art performance on a suite of density estimation tasks and outperforms {IAF} in variational autoencoders trained on binarized {MNIST}.},
	pages = {2078--2087},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},
	editor = {Dy, Jennifer and Krause, Andreas},
	date = {2018-07-10},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/24Y8E8I5/Huang et al. - 2018 - Neural Autoregressive Flows.pdf:application/pdf},
}

@article{papamakarios_normalizing_2021,
	title = {Normalizing Flows for Probabilistic Modeling and Inference},
	volume = {22},
	url = {http://jmlr.org/papers/v22/19-1028.html},
	pages = {1--64},
	number = {57},
	journaltitle = {Journal of Machine Learning Research},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	date = {2021},
	keywords = {generative models, invertible neural networks, normalizing flows, probabilistic inference, probabilistic modeling},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/HXEIC99R/Papamakarios et al. - 2021 - Normalizing Flows for Probabilistic Modeling and I.pdf:application/pdf},
}

@article{van_biesbroeck_generalized_2024,
	title = {Generalized mutual information and their reference priors under Csizar f-divergence},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	doi = {10.48550/arXiv.2310.10530},
	journaltitle = {{arXiv}.2310.10530},
	author = {Van Biesbroeck, Antoine},
	date = {2024},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/E3GASCF7/Van Biesbroeck - 2024 - Generalized mutual information and their reference.pdf:application/pdf},
}

@thesis{gauchy_uncertainty_2022,
	title = {Uncertainty quantification methodology for seismic fragility curves of mechanical structures : Application to a piping system of a nuclear power plant},
	url = {https://theses.hal.science/tel-04102809},
	institution = {Institut Polytechnique de Paris},
	type = {phdthesis},
	author = {Gauchy, Clément},
	date = {2022-11},
	keywords = {Design of experiments, Fiabilité sismique, Gaussian process, Industrie nucléaire, Nuclear industry, Planification d'expériences, Processus Gaussien, Quantification des incertitudes, Seismic reliability, Uncertainty quantification},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/64WWFE4J/Gauchy - 2022 - Uncertainty quantification methodology for seismic.pdf:application/pdf},
}

@article{kass_selection_1996,
	title = {The Selection of Prior Distributions by Formal Rules},
	volume = {91},
	doi = {10.1080/01621459.1996.10477003},
	pages = {1343--1370},
	number = {435},
	journaltitle = {Journal of the American Statistical Association},
	author = {Kass, Robert E. and Wasserman, Larry},
	date = {1996},
	note = {Publisher: {ASA} Website},
}

@article{berger_formal_2009,
	title = {The formal definition of reference priors},
	volume = {37},
	url = {https://doi.org/10.1214/07-AOS587},
	doi = {10.1214/07-AOS587},
	pages = {905--938},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Berger, James O. and Bernardo, José M. and Sun, Dongchu},
	date = {2009},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Amount of information, Bayesian asymptotics, consensus priors, Fisher information, Jeffreys priors, noninformative priors, objective priors, reference priors},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/8I73C3ZK/Berger et al. - 2009 - The Formal Definition of Reference Priors.pdf:application/pdf},
}

@article{van_biesbroeck_reference_2024,
	title = {Reference prior for Bayesian estimation of seismic fragility curves},
	volume = {76},
	doi = {10.1016/j.probengmech.2024.103622},
	pages = {103622},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Van Biesbroeck, Antoine and Gauchy, Clément and Feau, Cyril and Garnier, Josselin},
	date = {2024},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/ZF9XL3C4/Van Biesbroeck et al. - 2024 - Reference prior for Bayesian estimation of seismic.pdf:application/pdf},
}

@article{bernardo_reference_1979,
	title = {Reference Posterior Distributions for Bayesian Inference},
	volume = {41},
	doi = {10.1111/j.2517-6161.1979.tb01066.x},
	pages = {113--147},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society. Series B},
	author = {Bernardo, José M.},
	date = {1979-01},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/ZX2P6YBH/Bernardo - 1979 - Reference Posterior Distributions for Bayesian Inf.pdf:application/pdf},
}

@article{natarajan_reference_2000,
	title = {Reference Bayesian Methods for Generalized Linear Mixed Models},
	volume = {95},
	doi = {10.1080/01621459.2000.10473916},
	pages = {227--237},
	number = {449},
	journaltitle = {Journal of the American Statistical Association},
	author = {Natarajan, Ranjini and Kass, Robert E.},
	date = {2000},
	note = {Publisher: Taylor \& Francis},
}

@incollection{dey_reference_2005,
	title = {Reference Analysis},
	volume = {25},
	url = {https://www.sciencedirect.com/science/article/pii/S0169716105250022},
	series = {Handbook of Statistics},
	pages = {17--90},
	booktitle = {Bayesian Thinking},
	publisher = {Elsevier},
	author = {Bernardo, José M.},
	editor = {Dey, D. K. and Rao, C.R.},
	date = {2005},
	doi = {10.1016/S0169-7161(05)25002-2},
	note = {{ISSN}: 0169-7161},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/PESXTY9X/Bernardo - 2005 - Reference Analysis.pdf:application/pdf},
}

@article{kennedy_probabilistic_1980,
	title = {Probabilistic seismic safety study of an existing nuclear power plant},
	volume = {59},
	issn = {0029-5493},
	doi = {10.1016/0029-5493(80)90203-4},
	pages = {315--338},
	number = {2},
	journaltitle = {Nuclear Engineering and Design},
	author = {Kennedy, Robert P. and Cornell, C. Allin and Campbell, Robert D. and Kaplan, Stan J. and Perla, Harold F.},
	date = {1980},
}

@article{simpson_penalising_2017,
	title = {Penalising Model Component Complexity: A Principled, Practical Approach to Constructing Priors},
	volume = {32},
	doi = {10.1214/16-STS576},
	pages = {1--28},
	number = {1},
	journaltitle = {Statistical Science},
	author = {Simpson, Daniel and Rue, Håvard and Riebler, Andrea and Martins, Thiago G. and Sørbye, Sigrunn H.},
	date = {2017},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Bayesian theory, disease mapping, hierarchical models, information geometry, interpretable prior distributions, prior on correlation matrices},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/BSFFFIYL/Simpson et al. - 2017 - Penalising Model Component Complexity A Principle.pdf:application/pdf},
}

@article{gu_parallel_2016,
	title = {Parallel partial Gaussian process emulation for computer models with massive output},
	volume = {10},
	doi = {10.1214/16-AOAS934},
	pages = {1317--1347},
	number = {3},
	journaltitle = {The Annals of Applied Statistics},
	author = {Gu, Mengyang and Berger, James O.},
	date = {2016},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {computer model emulation, Gaussian process, objective Bayesian analysis, space–time coordinate},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/2XJDFJMR/Gu et Berger - 2016 - Parallel partial Gaussian process emulation for co.pdf:application/pdf},
}

@article{berger_overall_2015,
	title = {Overall Objective Priors},
	volume = {10},
	doi = {10.1214/14-BA915},
	pages = {189--221},
	number = {1},
	journaltitle = {Bayesian Analysis},
	author = {Berger, James O. and Bernardo, Jose M. and Sun, Dongchu},
	date = {2015},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Joint Reference Prior, Logarithmic Divergence, Multinomial Model, objective priors, Reference Analysis},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/J67JBAY5/Berger et al. - 2015 - Overall Objective Priors.pdf:application/pdf},
}

@thesis{mure_objective_2018,
	title = {Objective Bayesian analysis of Kriging models with anisotropic correlation kernel},
	url = {https://theses.hal.science/tel-02184403v1},
	institution = {Université Sorbonne Paris Cité},
	type = {phdthesis},
	author = {Muré, Joseph},
	date = {2018},
	annotation = {2018USPCC069},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/9G2L4LPR/Muré - 2018 - Objective Bayesian analysis of Kriging models with.pdf:application/pdf},
}

@article{dandrea_objective_2021,
	title = {Objective bayesian analysis for multiple repairable systems},
	volume = {16},
	doi = {10.1371/journal.pone.0258581},
	pages = {1--19},
	journaltitle = {{PLOS} {ONE}},
	author = {D’Andrea, Amanda M. E. and Tomazella, Vera L. D. and Aljohani, Hassan M. and Ramos, Pedro L. and Almeida, Marco P. and Louzada, Francisco and Verssani, Bruna A. W. and Gazon, Amanda B. and Afify, Ahmed Z.},
	date = {2021-11},
	note = {Publisher: Public Library of Science},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/YJ7GD479/D’Andrea et al. - 2021 - Objective bayesian analysis for multiple repairabl.pdf:application/pdf},
}

@inproceedings{nalisnick_learning_2017,
	title = {Learning Approximately Objective Priors},
	doi = {10.48550/arXiv.1704.01168},
	booktitle = {Proceedings of the 33rd Conference on Uncertainty in Artificial Intelligence ({UAI})},
	publisher = {Association for Uncertainty in Artificial Intelligence ({AUAI})},
	author = {Nalisnick, Eric and Smyth, Padhraic},
	date = {2017},
	note = {Place: Sydney, Australia},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/VRJVNTQK/Nalisnick et Smyth - 2017 - Learning Approximately Objective Priors.pdf:application/pdf},
}

@article{clarke_jeffreys_1994,
	title = {Jeffreys' prior is asymptotically least favorable under entropy risk},
	volume = {41},
	issn = {0378-3758},
	url = {https://www.sciencedirect.com/science/article/pii/0378375894901538},
	doi = {10.1016/0378-3758(94)90153-8},
	pages = {37--60},
	number = {1},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Clarke, Bertrand S. and Barron, Andrew R.},
	date = {1994},
}

@article{csiszar_information-type_1967,
	title = {Information-type measures of difference of probability distributions and indirect observation},
	volume = {2},
	pages = {229--318},
	journaltitle = {Studia Scientiarum Mathematicarum Hungarica},
	author = {Csiszár, Imre},
	date = {1967},
}

@article{bernardo_expected_1979,
	title = {Expected Information as Expected Utility},
	volume = {7},
	doi = {10.1214/aos/1176344689},
	pages = {686--690},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Bernardo, José M.},
	date = {1979},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Bayesian statistics, decision theory, Design of experiments, Information, scientific inference, Utility},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/I5QSHG6V/Bernardo - 1979 - Expected Information as Expected Utility.pdf:application/pdf},
}

@article{sainct_efficient_2020,
	title = {Efficient methodology for seismic fragility curves estimation by active learning on Support Vector Machines},
	volume = {86},
	doi = {10.1016/j.strusafe.2020.101972},
	pages = {101972},
	journaltitle = {Structural Safety},
	author = {Sainct, Rémi and Feau, Cyril and Martinez, Jean-Marc and Garnier, Josselin},
	date = {2020},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/7BKK4GSX/Sainct et al. - 2020 - Efficient methodology for seismic fragility curves.pdf:application/pdf},
}

@article{paulo_default_2005,
	title = {Default priors for Gaussian processes},
	volume = {33},
	doi = {10.1214/009053604000001264},
	pages = {556--582},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Paulo, Rui},
	date = {2005},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {computer model, frequentist coverage, Gaussian process, integrated likelihood, Jeffreys prior, posterior propriety, reference prior},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/X3FLQ6EI/Paulo - 2005 - Default priors for Gaussian processes.pdf:application/pdf},
}

@article{bioche_approximation_2016,
	title = {Approximation of improper priors},
	volume = {22},
	doi = {10.3150/15-bej708},
	number = {3},
	journaltitle = {Bernoulli},
	author = {Bioche, Christele and Druilhet, Pierre},
	date = {2016-08},
	note = {Publisher: Bernoulli Society for Mathematical Statistics and Probability},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/F4ZPKQQ9/Bioche et Druilhet - 2016 - Approximation of improper priors.pdf:application/pdf},
}

@book{mackay_information_2003,
	title = {Information Theory, Inference, and Learning Algorithms},
	publisher = {Copyright Cambridge University Press},
	author = {{MacKay}, D. J. C.},
	date = {2003},
}

@article{bousquet_eliciting_2008,
	title = {Eliciting vague but proper maximal entropy priors in Bayesian experiments},
	volume = {51},
	issn = {1613-9798},
	doi = {10.1007/s00362-008-0149-9},
	pages = {613--628},
	number = {3},
	journaltitle = {Statistical Papers},
	author = {Bousquet, Nicolas},
	date = {2008-06},
	note = {Publisher: Springer Science and Business Media {LLC}},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/H7KQ69IC/Bousquet - 2008 - Eliciting vague but proper maximal entropy priors .pdf:application/pdf},
}

@incollection{marzouk_sampling_2016,
	location = {Cham},
	title = {Sampling via Measure Transport: An Introduction},
	pages = {1--41},
	booktitle = {Handbook of Uncertainty Quantification},
	publisher = {Springer International Publishing},
	author = {Marzouk, Y. and Moselhy, T. and Parno, M. and Spantini, A.},
	date = {2016},
	doi = {10.1007/978-3-319-11259-6_23-1},
}

@article{morris_bayesian_1993,
	title = {Bayesian Design and Analysis of Computer Experiments: Use of Derivatives in Surface Prediction},
	volume = {35},
	doi = {10.1080/00401706.1993.10485320},
	pages = {243--255},
	number = {3},
	journaltitle = {Technometrics},
	author = {Morris, Max D. and Mitchell, Toby J. and Ylvisaker, Donald},
	date = {1993},
	note = {Publisher: {ASA} Website},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/SSU2QVEK/Morris et al. - 1993 - Bayesian Design and Analysis of Computer Experimen.pdf:application/pdf},
}

@inproceedings{kingma_auto-encoding_2014,
	title = {Auto-Encoding Variational Bayes},
	doi = {10.48550/arXiv.1312.6114},
	booktitle = {Proceedings of the 2nd International Conference on Learning Representations ({ICLR})},
	author = {Kingma, Diederik P. and Welling, Max},
	date = {2014},
	note = {Place: Banff, Canada},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/BKUMXSWC/Kingma et Welling - 2014 - Auto-Encoding Variational Bayes.pdf:application/pdf},
}

@article{li_robust_2021,
	title = {Robust estimation of {SARS}-{CoV}-2 epidemic in {US} counties},
	volume = {11},
	doi = {10.1038/s41598-021-90195-6},
	pages = {2045--2322},
	number = {11841},
	journaltitle = {Scientific Reports},
	author = {Li, Hanmo and Gu, Mengyang},
	date = {2021},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/FLZG2FXE/Li et Gu - 2021 - Robust estimation of SARS-CoV-2 epidemic in US cou.pdf:application/pdf},
}

@inproceedings{buchholz_quasi-monte_2018,
	title = {Quasi-Monte Carlo Variational Inference},
	volume = {80},
	url = {https://Proceedings.mlr.press/v80/buchholz18a.html},
	series = {Proceedings of Machine Learning Research},
	pages = {668--677},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Buchholz, Alexander and Wenzel, Florian and Mandt, Stephan},
	editor = {Dy, Jennifer and Krause, Andreas},
	date = {2018-07-10},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/CRWX7U4R/Buchholz et al. - 2018 - Quasi-Monte Carlo Variational Inference.pdf:application/pdf},
}

@incollection{dodge_kolmogorovsmirnov_2008,
	location = {New York, {NY}},
	title = {Kolmogorov–Smirnov Test},
	isbn = {978-0-387-32833-1},
	url = {https://doi.org/10.1007/978-0-387-32833-1_214},
	pages = {283--287},
	booktitle = {The Concise Encyclopedia of Statistics},
	publisher = {Springer New York},
	author = {Dodge, Yadolah},
	date = {2008},
	doi = {10.1007/978-0-387-32833-1_214},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/RHUQA685/Dodge - 2008 - Kolmogorov–Smirnov Test.pdf:application/pdf},
}

@article{gretton_kernel_2012,
	title = {A Kernel Two-Sample Test},
	volume = {13},
	url = {http://jmlr.org/papers/v13/gretton12a.html},
	pages = {723--773},
	number = {25},
	journaltitle = {Journal of Machine Learning Research},
	author = {Gretton, Arthur and Borgwardt, Karsten M. and Rasch, Malte J. and Schölkopf, Bernhard and Smola, Alexander},
	date = {2012},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/IXGJYSBD/Gretton et al. - 2012 - A Kernel Two-Sample Test.pdf:application/pdf},
}

@incollection{gelman_bayesian_2013,
	title = {Bayesian data analysis, third edition},
	pages = {293--300},
	publisher = {Chapman and Hall/{CRC}},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	date = {2013},
	doi = {10.1201/b16018},
}

@article{micchelli_universal_2006,
	title = {Universal Kernels},
	volume = {7},
	issn = {1532-4435},
	url = {http://jmlr.org/papers/v7/micchelli06a.html},
	abstract = {In this paper we investigate conditions on the features of a continuous kernel so that it may approximate an arbitrary continuous target function uniformly on any compact subset of the input space. A number of concrete examples are given of kernels with this universal approximating property.},
	pages = {2651--2667},
	journaltitle = {Journal of Machine Learning Research},
	author = {Micchelli, Charles A. and Xu, Yuesheng and Zhang, Haizhang},
	date = {2006-12},
	note = {Publisher: {JMLR}.org},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/XU8YB2G2/Micchelli et al. - 2006 - Universal Kernels.pdf:application/pdf},
}

@article{kobyzev_normalizing_2021,
	title = {Normalizing Flows: An Introduction and Review of Current Methods},
	volume = {43},
	doi = {10.1109/TPAMI.2020.2992934},
	pages = {3964--3979},
	number = {11},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
	date = {2021},
	keywords = {Computational modeling, Context modeling, density estimation, Estimation, Generative models, invertible neural networks, Jacobian matrices, Mathematical model, normalizing flows, Random variables, Training, variational inference},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/JRM56W4V/Kobyzev et al. - 2021 - Normalizing Flows An Introduction and Review of C.pdf:application/pdf},
}

@inproceedings{gao_deep_2022,
	title = {Deep Reference Priors: What is the best way to pretrain a model?},
	volume = {162},
	url = {https://Proceedings.mlr.press/v162/gao22d.html},
	series = {Proceedings of Machine Learning Research},
	pages = {7036--7051},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Gao, Yansong and Ramesh, Rahul and Chaudhari, Pratik},
	date = {2022-07-17},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/NKCR4XYN/Gao et al. - 2022 - Deep Reference Priors What is the best way to pre.pdf:application/pdf},
}

@incollection{nocedal_numerical_2006,
	title = {Numerical optimization},
	pages = {497--528},
	booktitle = {Springer Series in Operations Research and Financial Engineering},
	publisher = {Springer New York},
	author = {Nocedal, Jorge and Wright, Stephen J.},
	date = {2006},
	doi = {10.1007/978-0-387-40065-5_17},
	note = {Section: Penalty and Augmented Lagrangian Methods},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/ESRKK6N2/Nocedal et Wright - 2006 - Numerical optimization.pdf:application/pdf},
}

@misc{basir_adaptive_2023,
	title = {An adaptive augmented Lagrangian method for training physics and equality constrained artificial neural networks},
	url = {https://arxiv.org/abs/2306.04904},
	author = {Basir, Shamsulhaq and Senocak, Inanc},
	date = {2023},
	note = {\_eprint: 2306.04904},
	annotation = {{arXiv}},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/TF9LD6PS/Basir et Senocak - 2023 - An adaptive augmented Lagrangian method for traini.pdf:application/pdf},
}

@inproceedings{lafferty_iterative_2001,
	title = {Iterative Markov Chain Monte Carlo Computation of Reference Priors and Minimax Risk},
	doi = {10.48550/arXiv.1301.2286},
	pages = {293--300},
	booktitle = {Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence ({UAI})},
	publisher = {Morgan Kaufmann},
	author = {Lafferty, John D. and Wasserman, Larry A.},
	editor = {Breese, Jack S. and Koller, Daphne},
	date = {2001},
	note = {Place: Seattle, {USA}},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/4BPY9TR5/Lafferty et Wasserman - 2001 - Iterative Markov Chain Monte Carlo Computation of .pdf:application/pdf},
}

@article{kingma_introduction_2019,
	title = {An Introduction to Variational Autoencoders},
	volume = {12},
	issn = {1935-8245},
	url = {http://dx.doi.org/10.1561/2200000056},
	doi = {10.1561/2200000056},
	pages = {307--392},
	number = {4},
	journaltitle = {Foundations and Trends® in Machine Learning},
	author = {Kingma, Diederik P. and Welling, Max},
	date = {2019},
	note = {Publisher: Now Publishers},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/K8WPL6WK/Kingma et Welling - 2019 - An Introduction to Variational Autoencoders.pdf:application/pdf},
}

@thesis{bioche_approximation_2015,
	title = {Approximation de lois impropres et applications},
	url = {https://theses.hal.science/tel-01308523},
	institution = {Université Blaise Pascal - Clermont-Ferrand {II}},
	type = {Theses},
	author = {Bioche, Christèle},
	date = {2015-11},
	note = {Issue: 2015CLF22626},
	keywords = {A priori conjugués, A priori de référence, A priori impropres, A priori non-informatifs, A priori vagues, Bayesian statistic, Conjugate prior, Convergence d'a priori, Convergence logarithmique, Convergence of priors, Improper prior, Jeffreys-Lindley paradox, Logarithmic convergence, Noninformative prior, Paradoxe de Jeffreys-Lindley, Reference prior, Removal sampling, Statistiques bayésiennes, Vague prior},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/DGT9QI8F/Bioche - 2015 - Approximation de lois impropres et applications.pdf:application/pdf},
}

@inproceedings{paszke_pytorch_2019,
	title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
	volume = {32},
	url = {https://Proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and {DeVito}, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d' and Fox, E. and Garnett, R.},
	date = {2019},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/UBDDFRDI/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Dee.pdf:application/pdf},
}

@inproceedings{jang_categorical_2017,
	title = {Categorical Reparameterization with Gumbel-Softmax},
	url = {https://openreview.net/forum?id=rkE3y85ee},
	doi = {10.48550/arXiv.1611.01144},
	booktitle = {Proceedings of the 5th International Conference on Learning Representations ({ICLR})},
	author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
	date = {2017},
	note = {Place: Toulon, France},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/98MKTAUD/Jang et al. - 2017 - Categorical Reparameterization with Gumbel-Softmax.pdf:application/pdf},
}

@inproceedings{gauchy_inference_2023,
	title = {Inférence variationnelle de lois a priori de référence},
	url = {https://jds2023.sciencesconf.org/resource/page/id/19},
	booktitle = {Proceedings des 54èmes Journées de Statistiques ({JdS})},
	publisher = {{SFDS}},
	author = {Gauchy, Clément and Van Biesbroeck, Antoine and Feau, Cyril and Garnier, Josselin},
	date = {2023-07},
}

@inproceedings{kingma_adam_2015,
	title = {Adam: A Method for Stochastic Optimization},
	doi = {10.48550/arXiv.1412.6980},
	booktitle = {Proceedings of the 3rd International Conference on Learning Representations ({ICLR})},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	date = {2015},
	note = {Place: San Diego, {USA}},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/U7YVYGJT/Kingma et Ba - 2015 - Adam A Method for Stochastic Optimization.pdf:application/pdf},
}

@book{press_subjective_2009,
	title = {Subjective and objective Bayesian statistics: principles, models, and applications},
	publisher = {John Wiley \& Sons},
	author = {Press, S James},
	date = {2009},
}

@article{jaynes_information_1957,
	title = {Information Theory and Statistical Mechanics},
	volume = {106},
	url = {https://link.aps.org/doi/10.1103/PhysRev.106.620},
	doi = {10.1103/PhysRev.106.620},
	pages = {620--630},
	number = {4},
	journaltitle = {Phys. Rev.},
	author = {Jaynes, E. T.},
	date = {1957-05},
	note = {Publisher: American Physical Society},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/MQHU6LL6/Jaynes - 1957 - Information Theory and Statistical Mechanics.pdf:application/pdf},
}

@article{zellner_models_1996,
	title = {Models, prior information, and Bayesian analysis},
	volume = {75},
	issn = {0304-4076},
	doi = {10.1016/0304-4076(95)01768-2},
	pages = {51--68},
	number = {1},
	journaltitle = {Journal of Econometrics},
	author = {Zellner, Arnold},
	date = {1996},
}

@article{reid_aspects_2003,
	title = {Some aspects of matching priors},
	pages = {31--43},
	journaltitle = {Lecture Notes-Monograph Series},
	author = {Reid, N and Mukerjee, R and Fraser, {DAS}},
	date = {2003},
	note = {Publisher: {JSTOR}},
}

@article{soofi_principal_2000,
	title = {Principal Information Theoretic Approaches},
	volume = {95},
	doi = {10.1080/01621459.2000.10474346},
	pages = {1349--1353},
	number = {452},
	journaltitle = {Journal of the American Statistical Association},
	author = {Soofi, Ehsan S.},
	date = {2000},
	note = {Publisher: {ASA} Website},
}

@book{bernardo_bayesian_1994,
	edition = {1st},
	title = {Bayesian Theory},
	isbn = {0-471-49464-X},
	series = {Wiley Series in Probability and Statistics},
	publisher = {Wiley},
	author = {Bernardo, José M. and Smith, Adrian F. M.},
	date = {1994},
}

@article{luco_structure-specific_2007,
	title = {Structure-Specific Scalar Intensity Measures for Near-Source and Ordinary Earthquake Ground Motions},
	volume = {23},
	doi = {10.1193/1.2723158},
	pages = {357--392},
	number = {2},
	journaltitle = {Earthquake Spectra},
	author = {Luco, Nicolas and Cornell, C. Allin},
	date = {2007},
}

@article{radu_earthquake-source-based_2018,
	title = {An earthquake-source-based metric for seismic fragility analysis},
	volume = {16},
	doi = {10.1007/s10518-018-0341-9},
	journaltitle = {Bull Earthquake Eng},
	author = {Radu, Alin and Grigoriu, Mircea Dan},
	date = {2018},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/98TJWYGW/Radu et Grigoriu - 2018 - An earthquake-source-based metric for seismic frag.pdf:application/pdf},
}

@article{ellingwood_validation_1990,
	title = {Validation studies of seismic {PRAs}},
	volume = {123},
	issn = {0029-5493},
	doi = {10.1016/0029-5493(90)90237-R},
	pages = {189--196},
	number = {2},
	journaltitle = {Nuclear Engineering and Design},
	author = {Ellingwood, Bruce},
	date = {1990},
}

@article{buratti_empirical_2017,
	title = {Empirical seismic fragility for the precast {RC} industrial buildings damaged by the 2012 Emilia (Italy) earthquakes},
	volume = {46},
	doi = {10.1002/eqe.2906},
	pages = {2317--2335},
	number = {14},
	journaltitle = {Earthquake Engineering \& Structural Dynamics},
	author = {Buratti, Nicola and Minghini, Fabio and Ongaretto, Elena and Savoia, Marco and Tullini, Nerio},
	date = {2017},
	keywords = {Emilia earthquakes, precast {RC} buildings, seismic damage, seismic fragility, seismic risk},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/WJ6KK478/Buratti et al. - 2017 - Empirical seismic fragility for the precast RC ind.pdf:application/pdf},
}

@article{noh_development_2014,
	title = {Development of empirical and analytical fragility functions using kernel smoothing methods},
	volume = {44},
	doi = {10.1002/eqe.2505},
	pages = {1163--1180},
	number = {8},
	journaltitle = {Earthquake Engineering \& Structural Dynamics},
	author = {Noh, Hae Young and Lallemant, David and Kiremidjian, Anne S.},
	date = {2014},
	keywords = {fragility function, kernel smoothing, non-parametric analysis, performance-based earthquake engineering, uncertainty in damage, uncertainty in ground motion},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/Y45TJJX6/Noh et al. - 2014 - Development of empirical and analytical fragility .pdf:application/pdf},
}

@article{laguerre_empirical_2024,
	title = {Empirical Fragility Analysis of Haitian Reinforced Concrete and Masonry Buildings},
	volume = {14},
	issn = {2075-5309},
	doi = {10.3390/buildings14030792},
	pages = {792},
	number = {3},
	journaltitle = {Buildings},
	author = {Laguerre, Marc-Ansy and Salehi, Mohammad and Desroches, Reginald},
	date = {2024},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/8UZJKABM/Laguerre et al. - 2024 - Empirical Fragility Analysis of Haitian Reinforced.pdf:application/pdf},
}

@article{lee_efficient_2023,
	title = {On efficient seismic fragility assessment using sequential Bayesian inference and truncation scheme: A case study of shear wall structure},
	volume = {289},
	issn = {0045-7949},
	doi = {10.1016/j.compstruc.2023.107150},
	pages = {107150},
	journaltitle = {Computers \& Structures},
	author = {Lee, Sangwoo and Kwag, Shinyoung and Ju, Bu-seog},
	date = {2023},
	keywords = {Fragility assessment, Nonlinear time history analysis, Sequential Bayesian Inference, Shear wall structures, Truncation Scheme},
}

@article{ghobarah_performance-based_2001,
	title = {Performance-based design in earthquake engineering: state of development},
	volume = {23},
	issn = {0141-0296},
	doi = {10.1016/S0141-0296(01)00036-0},
	pages = {878--884},
	number = {8},
	journaltitle = {Engineering Structures},
	author = {Ghobarah, Ahmed},
	date = {2001},
	keywords = {Challenges, Design criteria, Design procedures, Earthquake hazard, Evaluation, Future trends, Performance based-design, Performance objectives},
}

@article{khansefid_fragility_2023,
	title = {Fragility and comfortability curves development and seismic risk assessment of a masonry building under earthquakes induced by geothermal power plants operation},
	volume = {103},
	issn = {0167-4730},
	doi = {10.1016/j.strusafe.2023.102343},
	pages = {102343},
	journaltitle = {Structural Safety},
	author = {Khansefid, Ali and Yadollahi, Seyed Mahmoudreza and Taddei, Francesca and Müller, Gerhard},
	date = {2023},
	keywords = {Comfortability curve, Fragility curve, {GPPs}, Induced seismicity, Masonry building},
}

@article{ciano_novel_2022,
	title = {A novel approach to improve accuracy in seismic fragility analysis: The modified intensity measure method},
	volume = {69},
	issn = {0266-8920},
	doi = {10.1016/j.probengmech.2022.103301},
	pages = {103301},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Ciano, Matteo and Gioffrè, Massimiliano and Grigoriu, Mircea},
	date = {2022},
	keywords = {Complex mdof structural systems, Earthquake engineering, Fragility analysis, Fragility curves, Modified seismic intensity measures ({mIMs}), Monte Carlo simulation, Seismic intensity measures ({IMs})},
}

@article{ciano_role_2020,
	title = {The role of intensity measures on the accuracy of seismic fragilities},
	volume = {60},
	issn = {0266-8920},
	doi = {10.1016/j.probengmech.2020.103041},
	pages = {103041},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Ciano, Matteo and Gioffrè, Massimiliano and Grigoriu, Mircea},
	date = {2020},
	keywords = {Complex mdof structural systems, Earthquake engineering, Fragility curves, Seismic intensity measures ({IMs}), Epsilon(), Nonlinear response},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/U3585FAG/Ciano et al. - 2020 - The role of intensity measures on the accuracy of seismic fragilities.pdf:application/pdf},
}

@article{zhu_seismic_2023,
	title = {Seismic fragility analysis using stochastic polynomial chaos expansions},
	volume = {72},
	issn = {0266-8920},
	doi = {10.1016/j.probengmech.2023.103413},
	pages = {103413},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Zhu, Xujia and Broccardo, Marco and Sudret, Bruno},
	date = {2023},
	keywords = {Earthquake engineering, Fragility functions, Polynomial chaos expansion, Stochastic simulator},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/2JYULWLE/Zhu et al. - 2023 - Seismic fragility analysis using stochastic polyno.pdf:application/pdf},
}

@book{ito_diffusion_1974,
	location = {Berlin},
	title = {Diffusion processes and their sample paths},
	isbn = {978-3-540-60629-1},
	publisher = {Springer-Verlag},
	author = {Ito, Kiyosi and {McKean}, Henry P.},
	date = {1974},
}

@misc{cea_cast3m_2019,
	title = {{CAST}3M},
	url = {http://www-cast3m.cea.fr/},
	author = {{CEA}},
	date = {2019},
}

@article{tabandeh_physics-based_2020,
	title = {Physics-based probabilistic models: Integrating differential equations and observational data},
	volume = {87},
	issn = {0167-4730},
	doi = {10.1016/j.strusafe.2020.101981},
	pages = {101981},
	journaltitle = {Structural Safety},
	author = {Tabandeh, Armin and Asem, Pouyan and Gardoni, Paolo},
	date = {2020},
}

@article{katayama_bayesian-estimation-based_2021,
	title = {Bayesian-estimation-based method for generating fragility curves for high-fidelity seismic probability risk assessment},
	volume = {58},
	doi = {10.1080/00223131.2021.1931517},
	pages = {1220--1234},
	number = {11},
	journaltitle = {Journal of Nuclear Science and Technology},
	author = {Katayama, Yoshifumi and Ohtori, Yasuki and Sakai, Toshiaki and Muta, Hitoshi},
	date = {2021},
	note = {Publisher: Taylor \& Francis},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/84KJ8FJX/Katayama et al. - 2021 - Bayesian-estimation-based method for generating fr.pdf:application/pdf},
}

@article{ge_developing_2023,
	title = {Developing region-specific fragility function for predicting probability of liquefaction induced ground failure},
	volume = {71},
	issn = {0266-8920},
	doi = {10.1016/j.probengmech.2022.103381},
	pages = {103381},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Ge, Yixun and Zhang, Zechao and Zhang, Jie and Huang, Hongwei},
	date = {2023},
	keywords = {Failure probability, Hierarchical Bayesian Model, Model uncertainty, Soil liquefaction},
}

@article{jeon_parameterized_2019,
	title = {Parameterized Seismic Fragility Curves for Curved Multi-frame Concrete Box-Girder Bridges Using Bayesian Parameter Estimation},
	volume = {23},
	doi = {10.1080/13632469.2017.1342291},
	pages = {954--979},
	number = {6},
	journaltitle = {Journal of Earthquake Engineering},
	author = {Jeon, Jong-Su and Mangalathu, Sujith and Song, Junho and Desroches, Reginald},
	date = {2019},
	note = {Publisher: Taylor \& Francis},
}

@article{tadinada_structural_2017,
	title = {Structural fragility of T-joint connections in large-scale piping systems using equivalent elastic time-history simulations},
	volume = {65},
	issn = {0167-4730},
	doi = {10.1016/j.strusafe.2016.12.003},
	pages = {49--59},
	journaltitle = {Structural Safety},
	author = {Tadinada, Sashi Kanth and Gupta, Abhinav},
	date = {2017},
	keywords = {Bayesian updating, Earthquake time history analysis, Equivalent linearization, Piping systems, Structural fragility},
}

@article{koutsourelakis_assessing_2010,
	title = {Assessing structural vulnerability against earthquakes using multi-dimensional fragility surfaces: A Bayesian framework},
	volume = {25},
	issn = {0266-8920},
	doi = {10.1016/j.probengmech.2009.05.005},
	pages = {49--60},
	number = {1},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Koutsourelakis, P. Steve},
	date = {2010},
}

@article{zentner_numerical_2010,
	title = {Numerical computation of fragility curves for {NPP} equipment},
	volume = {240},
	issn = {0029-5493},
	doi = {10.1016/j.nucengdes.2010.02.030},
	pages = {1614--1621},
	number = {6},
	journaltitle = {Nuclear Engineering and Design},
	author = {Zentner, Irmela},
	date = {2010},
}

@article{gardoni_probabilistic_2002,
	title = {Probabilistic Capacity Models and Fragility Estimates for Reinforced Concrete Columns based on Experimental Observations},
	volume = {128},
	doi = {10.1061/(ASCE)0733-9399(2002)128:10(1024)},
	pages = {1024--1038},
	number = {10},
	journaltitle = {Journal of Engineering Mechanics},
	author = {Gardoni, Paolo and Der Kiureghian, Armen and Mosalam, Khalid M.},
	date = {2002},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/YQAZN3U4/Gardoni et al. - 2002 - Probabilistic Capacity Models and Fragility Estima.pdf:application/pdf},
}

@article{gauchy_importance_2021,
	title = {Importance sampling based active learning for parametric seismic fragility curve estimation},
	rights = {Creative Commons Attribution 4.0 International},
	doi = {10.48550/arxiv.2109.04323},
	journaltitle = {{arXiv}.2109.04323},
	author = {Gauchy, Clement and Feau, Cyril and Garnier, Josselin},
	date = {2021},
	keywords = {62F35, 62L05, 62P30, {FOS}: Computer and information sciences, Machine Learning (cs.{LG}), Machine Learning (stat.{ML}), Methodology (stat.{ME})},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/C4UFJIEF/Gauchy et al. - 2021 - Importance sampling based active learning for para.pdf:application/pdf},
}

@article{damblin_approche_2014,
	title = {Approche décisionnelle bayésienne pour estimer une courbe de fragilité},
	volume = {155},
	url = {https://hal.archives-ouvertes.fr/hal-01545648},
	pages = {78--103},
	number = {3},
	journaltitle = {Journal de la Societe Française de Statistique},
	author = {Damblin, Guillaume and Keller, Merlin and Pasanisi, Alberto and Barbillon, Pierre and Parent, Éric},
	date = {2014},
	note = {Publisher: Societe Française de Statistique et Societe Mathematique de France},
	keywords = {Bayesian theory, analyse de risque, analyse décisionnelle, computer experiments, courbes de fragilité, decision analysis, expériences numériques, fonction de coût, fragility curves, loss function, risk analysis, théorie bayésienne},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/ZWYI9BN3/Damblin et al. - 2014 - Approche décisionnelle bayésienne pour estimer une.pdf:application/pdf},
}

@article{kwag_computationally_2018,
	title = {Computationally efficient fragility assessment using equivalent elastic limit state and Bayesian updating},
	volume = {197},
	issn = {0045-7949},
	doi = {10.1016/j.compstruc.2017.11.011},
	pages = {1--11},
	journaltitle = {Computers \& Structures},
	author = {Kwag, Shinyoung and Gupta, Abhinav},
	date = {2018},
}

@article{choe_closed-form_2007,
	title = {Closed-Form Fragility Estimates, Parameter Sensitivity, and Bayesian Updating for {RC} Columns},
	volume = {133},
	doi = {10.1061/(ASCE)0733-9399(2007)133:7(833)},
	pages = {833--843},
	number = {7},
	journaltitle = {Journal of Engineering Mechanics},
	author = {Choe, Do-Eun and Gardoni, Paolo and Rosowsky, David},
	date = {2007},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/PEZLLD5A/Choe et al. - 2007 - Closed-Form Fragility Estimates, Parameter Sensiti.pdf:application/pdf},
}

@article{straub_improved_2008,
	title = {Improved seismic fragility modeling from empirical data},
	volume = {30},
	doi = {10.1016/j.strusafe.2007.05.004},
	pages = {320--336},
	number = {4},
	journaltitle = {Structural Safety},
	author = {Straub, Daniel and Der Kiureghian, Armen},
	date = {2008-07},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/TMZCTVX3/Straub et Der Kiureghian - 2008 - Improved seismic fragility modeling from empirical.pdf:application/pdf},
}

@article{wang_bayesian_2018,
	title = {A Bayesian framework for estimating fragility curves based on seismic damage data and numerical simulations by adaptive neural networks},
	volume = {338},
	issn = {0029-5493},
	doi = {10.1016/j.nucengdes.2018.08.016},
	pages = {232--246},
	journaltitle = {Nuclear Engineering and Design},
	author = {Wang, Zhiyi and Zentner, Irmela and Zio, Enrico},
	date = {2018},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/3EGNAX6G/Wang et al. - 2018 - A Bayesian framework for estimating fragility curv.pdf:application/pdf},
}

@article{gauchy_uncertainty_2024,
	title = {Uncertainty quantification and global sensitivity analysis of seismic fragility curves using kriging},
	volume = {14},
	doi = {10.1615/Int.J.UncertaintyQuantification.2023046480},
	pages = {39--63},
	number = {4},
	journaltitle = {International Journal for Uncertainty Quantification},
	author = {Gauchy, Clement and Feau, Cyril and Garnier, Josselin},
	date = {2024},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/HR8M7E8P/Gauchy et al. - 2024 - Uncertainty quantification and global sensitivity .pdf:application/pdf},
}

@article{gidaris_kriging_2015,
	title = {Kriging metamodeling in seismic risk assessment based on stochastic ground motion models},
	volume = {44},
	doi = {10.1002/eqe.2586},
	pages = {2377--2399},
	number = {14},
	journaltitle = {Earthquake Engineering \& Structural Dynamics},
	author = {Gidaris, Ioannis and Taflanidis, Alexandros A. and Mavroeidis, George P.},
	date = {2015},
	keywords = {seismic risk, kriging, stochastic ground motion models, surrogate modeling},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/H9J6839U/Gidaris et al. - 2015 - Kriging metamodeling in seismic risk assessment ba.pdf:application/pdf},
}

@article{wang_seismic_2018,
	title = {Seismic fragility analysis with artificial neural networks: Application to nuclear power plant equipment},
	volume = {162},
	issn = {0141-0296},
	doi = {10.1016/j.engstruct.2018.02.024},
	pages = {213--225},
	journaltitle = {Engineering Structures},
	author = {Wang, Zhiyi and Pedroni, Nicola and Zentner, Irmela and Zio, Enrico},
	date = {2018},
	keywords = {Fragility curve, Artificial neural network, Feature selection, Prediction uncertainty, Seismic probabilistic risk assessment},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/WWRCBJQ2/Wang et al. - 2018 - Seismic fragility analysis with artificial neural .pdf:application/pdf},
}

@article{mai_seismic_2017,
	title = {Seismic fragility curves for structures using non-parametric representations},
	volume = {11},
	doi = {10.1007/s11709-017-0385-y},
	pages = {169--186},
	number = {2},
	journaltitle = {Frontiers of Structural and Civil Engineering},
	author = {Mai, Chu and Konakli, Katerina and Sudret, Bruno},
	date = {2017-04},
	note = {Publisher: Springer Science and Business Media {LLC}},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/LPRDCWK7/Mai et al. - 2017 - Seismic fragility curves for structures using non-.pdf:application/pdf},
}

@article{gentile_gaussian_2020,
	title = {Gaussian process regression for seismic fragility assessment of building portfolios},
	volume = {87},
	issn = {0167-4730},
	doi = {10.1016/j.strusafe.2020.101980},
	pages = {101980},
	journaltitle = {Structural Safety},
	author = {Gentile, Roberto and Galasso, Carmine},
	date = {2020},
	keywords = {Building portfolios, Building-to-building variability, Gaussian process regression, Mechanics-based approaches, Metamodels, Seismic fragility},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/R9TABVQA/Gentile et Galasso - 2020 - Gaussian process regression for seismic fragility .pdf:application/pdf},
}

@article{mitropoulou_developing_2011,
	title = {Developing fragility curves based on neural network {IDA} predictions},
	volume = {33},
	issn = {0141-0296},
	doi = {10.1016/j.engstruct.2011.07.005},
	pages = {3409--3421},
	number = {12},
	journaltitle = {Engineering Structures},
	author = {Mitropoulou, Chara Ch. and Papadrakakis, Manolis},
	date = {2011},
	keywords = {Fragility analysis, Harmony search, Incremental dynamic analysis, Neural networks, Reinforced concrete buildings, Vertical statistics},
}

@article{mai_surrogate_2016,
	title = {Surrogate modeling for stochastic dynamical systems by combining nonlinear autoregressive with exogenous input models and polynomial chaos expansions},
	volume = {6},
	doi = {10.1615/Int.J.UncertaintyQuantification.2016016603},
	pages = {313--339},
	journaltitle = {International Journal for Uncertainty Quantification},
	author = {Mai, Chu and Spiridonakos, Minas. D. and Chatzi, Eleni and Sudret, Bruno},
	date = {2016-01},
}

@article{kiani_application_2019,
	title = {On the application of machine learning techniques to derive seismic fragility curves},
	volume = {218},
	issn = {0045-7949},
	doi = {10.1016/j.compstruc.2019.03.004},
	pages = {108--122},
	journaltitle = {Computers \& Structures},
	author = {Kiani, Jalal and Camp, Charles and Pezeshk, Shahram},
	date = {2019},
}

@article{bernier_fragility_2019,
	title = {Fragility and risk assessment of aboveground storage tanks subjected to concurrent surge, wave, and wind loads},
	volume = {191},
	issn = {0951-8320},
	doi = {10.1016/j.ress.2019.106571},
	pages = {106571},
	journaltitle = {Reliability Engineering \& System Safety},
	author = {Bernier, Carl and Padgett, Jamie E.},
	date = {2019},
	keywords = {Fragility model, Multi-hazard, Risk assessment, Storage tank, Storm surge, Wave, Wind},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/CMJGUAP9/Bernier et Padgett - 2019 - Fragility and risk assessment of aboveground storage tanks subjected to concurrent surge, wave, and.pdf:application/pdf},
}

@article{grigoriu_are_2021,
	title = {Are seismic fragility curves fragile?},
	volume = {63},
	issn = {0266-8920},
	doi = {10.1016/j.probengmech.2020.103115},
	pages = {103115},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Grigoriu, Mircea Dan and Radu, Alin},
	date = {2021},
	keywords = {Fragility curves, Conditional probability, Conditional response spectrum, Fragility surfaces, Ground acceleration, Stochastic process},
	file = {Version acceptée:/Users/antoinevanbiesbroeck/Zotero/storage/J7JGPM4W/Grigoriu et Radu - 2021 - Are seismic fragility curves fragile.pdf:application/pdf},
}

@article{mandal_seismic_2016,
	title = {Seismic fragility analysis of a typical Indian {PHWR} containment: Comparison of fragility models},
	volume = {58},
	issn = {0167-4730},
	doi = {10.1016/j.strusafe.2015.08.003},
	pages = {11--19},
	journaltitle = {Structural Safety},
	author = {Mandal, Tushar K. and Ghosh, Siddhartha and Pujari, Nikil N.},
	date = {2016},
	keywords = {Incremental dynamic analysis, Fragility, Nuclear containment, Probabilistic safety assessment, Seismic},
}

@article{kim_development_2004,
	title = {Development of fragility curves of bridges retrofitted by column jacketing},
	volume = {19},
	issn = {0266-8920},
	doi = {10.1016/j.probengmech.2003.11.009},
	pages = {105--112},
	number = {1},
	journaltitle = {Probabilistic Engineering Mechanics},
	author = {Kim, Sang-Hoon and Shinozuka, Masanobu},
	date = {2004},
}

@article{ellingwood_earthquake_2001,
	title = {Earthquake risk assessment of building structures},
	volume = {74},
	issn = {0951-8320},
	doi = {10.1016/S0951-8320(01)00105-3},
	pages = {251--262},
	number = {3},
	journaltitle = {Reliability Engineering \& System Safety},
	author = {Ellingwood, Bruce R.},
	date = {2001},
}

@article{shinozuka_statistical_2000,
	title = {Statistical Analysis of Fragility Curves},
	volume = {126},
	doi = {10.1061/(ASCE)0733-9399(2000)126:12(1224)},
	pages = {1224--1231},
	number = {12},
	journaltitle = {Journal of Engineering Mechanics},
	author = {Shinozuka, Masanobu and Feng, M. Q. and Lee, Jongheon and Naganuma, Toshihiko},
	date = {2000},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/N6A8RNP7/Shinozuka et al. - 2000 - Statistical Analysis of Fragility Curves.pdf:application/pdf},
}

@article{porter_creating_2007,
	title = {Creating Fragility Functions for Performance-Based Earthquake Engineering},
	volume = {23},
	doi = {10.1193/1.2720892},
	pages = {471--489},
	number = {2},
	journaltitle = {Earthquake Spectra},
	author = {Porter, Keith and Kennedy, Robert P. and Bachman, Robert},
	date = {2007},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/D5ACIW7B/Porter et al. - 2007 - Creating Fragility Functions for Performance-Based.pdf:application/pdf},
}

@article{wang_influence_2020,
	title = {Influence of Input Motion's Control Point Location in Nonlinear {SSI} Analysis of Equipment Seismic Fragilities: Case Study on the Kashiwazaki-Kariwa {NPP}},
	volume = {177},
	issn = {1420-9136},
	doi = {10.1007/s00024-020-02467-3},
	pages = {2391--2409},
	journaltitle = {Pure and Applied Geophysics},
	author = {Wang, Fan and Feau, Cyril},
	date = {2020},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/7EX9JF86/Wang et Feau - 2020 - Influence of Input Motion's Control Point Location.pdf:application/pdf},
}

@article{zhao_seismic_2020,
	title = {Seismic fragility analysis of {AP}1000 {SB} considering fluid-structure interaction effects},
	volume = {23},
	issn = {2352-0124},
	doi = {10.1016/j.istruc.2019.11.003},
	pages = {103--110},
	journaltitle = {Structures},
	author = {Zhao, Chnfeng and Yu, Na and Mo, Yilung},
	date = {2020},
	keywords = {Fluid-structure interaction, Maximum likelihood estimation, Quadratic regression, Shield building, Vulnerability assessment},
}

@article{lallemant_statistical_2015,
	title = {Statistical procedures for developing earthquake damage fragility curves},
	volume = {44},
	doi = {10.1002/eqe.2522},
	pages = {1373--1389},
	number = {9},
	journaltitle = {Earthquake Engineering \& Structural Dynamics},
	author = {Lallemant, David and Kiremidjian, Anne and Burton, Henry},
	date = {2015},
	keywords = {kernel smoothing, fragility curves, generalized additive model, generalized linear model, maximum likelihood estimation},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/9PSNYREU/Lallemant et al. - 2015 - Statistical procedures for developing earthquake d.pdf:application/pdf},
}

@book{noauthor_proceedings_2004,
	location = {University of California, Berkeley},
	title = {Proceedings of the International Workshop on Performance-Based Seismic Design - Concepts and Implementation},
	series = {{PEER} Report 2004-05},
	publisher = {{PEER} Center},
	date = {2004},
}

@inproceedings{cornell_hazard_2004,
	location = {University of California, Berkeley},
	title = {{HAZARD}, {GROUND} {MOTIONS} {AND} {PROBABILISTIC} {ASSESSMENTS} {FOR} {PBSD}},
	pages = {39--52},
	booktitle = {Proceedings of the International Workshop on Performance-Based Seismic Design - Concepts and Implementation},
	publisher = {{PEER} Center},
	author = {Cornell, C. Allin},
	date = {2004},
	note = {event-place: {BLED}, {SLOVENIA}},
}

@article{kennedy_seismic_1984,
	title = {Seismic fragilities for nuclear power plant risk studies},
	volume = {79},
	doi = {10.1016/0029-5493(84)90188-2},
	pages = {47--68},
	number = {1},
	journaltitle = {Nuclear Engineering and Design},
	author = {Kennedy, Robert P. and Ravindra, Mayasandra K.},
	date = {1984},
}

@article{gehl_influence_2015,
	title = {Influence of the Number of Dynamic Analyses on the Accuracy of Structural Response Estimates},
	volume = {31},
	doi = {10.1193/102912EQS320M},
	pages = {97--113},
	number = {1},
	journaltitle = {Earthquake Spectra},
	author = {Gehl, Pierre and Douglas, John and Seyedi, Darius M.},
	date = {2015-02},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/KB2SVCQZ/Gehl et al. - 2015 - Influence of the Number of Dynamic Analyses on the.pdf:application/pdf},
}

@article{baker_efficient_2015,
	title = {Efficient analytical fragility function fitting using dynamic structural analysis},
	volume = {31},
	doi = {10.1193/021113EQS025M},
	pages = {579--599},
	number = {1},
	journaltitle = {Earthquake Spectra},
	author = {Baker, Jack W.},
	date = {2015-02},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/9L8H77H6/Baker - 2015 - Efficient analytical fragility function fitting us.pdf:application/pdf},
}

@book{robert_bayesian_2007,
	edition = {2},
	title = {The Bayesian Choice},
	isbn = {978-0-387-95231-4},
	series = {Texts in Statistics},
	publisher = {Springer},
	author = {Robert, Christian},
	date = {2007},
}

@book{wasserman_all_2004,
	edition = {2},
	title = {All of statistics : a concise course in statistical inference},
	isbn = {978-1-4419-2322-6},
	series = {Texts in Statistics},
	publisher = {Springer},
	author = {Wasserman, Larry},
	date = {2004},
}

@article{kennedy_risk_1999,
	title = {Risk based seismic design criteria},
	volume = {192},
	issn = {0029-5493},
	doi = {10.1016/S0029-5493(99)00102-8},
	pages = {117--135},
	number = {2},
	journaltitle = {Nuclear Engineering and Design},
	author = {Kennedy, Robert P.},
	date = {1999},
}

@article{park_survey_1998,
	title = {Survey of seismic fragilities used in {PRA} studies of nuclear power plants},
	volume = {62},
	issn = {0951-8320},
	doi = {10.1016/S0951-8320(98)00019-2},
	pages = {185--195},
	number = {3},
	journaltitle = {Reliability Engineering \& System Safety},
	author = {Park, Young-Ji and Hofmayer, Charles H. and Chokshi, Nilesh C.},
	date = {1998},
	keywords = {Nuclear power plants, {PRA}, Seismic fragilities},
}

@article{jaynes_rationale_1982,
	title = {On the rationale of maximum-entropy methods},
	volume = {70},
	doi = {10.1109/proc.1982.12425},
	pages = {939--952},
	number = {9},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Jaynes, Edwin T.},
	date = {1982-09},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/INMEEXG6/Jaynes - 1982 - On the rationale of maximum-entropy methods.pdf:application/pdf},
}

@book{stroock_probability_1993,
	edition = {1},
	title = {Probability Theory, an Analytical View},
	isbn = {0-521-43123-9},
	publisher = {Cambridge University Press},
	author = {Stroock, Daniel W.},
	date = {1993},
}

@book{kielhofer_calculus_2018,
	edition = {1},
	title = {Calculus of Variations},
	volume = {67},
	isbn = {978-3-319-71122-5},
	series = {Texts in Applied Mathematics},
	publisher = {Springer},
	author = {Kielhöfer, Hansjörg},
	date = {2018},
}

@book{gelman_bayesian_2013-1,
	edition = {3},
	title = {Bayesian data analysis},
	isbn = {978-1-4398-4095-5},
	series = {Texts in Statistical Science},
	publisher = {Chapman and Hall/{CRC}},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B.},
	date = {2013},
}

@article{csiszar_i-divergence_1975,
	title = {I-Divergence Geometry of Probability Distributions and Minimization Problems},
	volume = {3},
	doi = {10.1214/aop/1176996454},
	pages = {146--158},
	number = {1},
	journaltitle = {The Annals of Probability},
	author = {Csiszár, Imre},
	date = {1975-02},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/X8G8CGKY/Csiszár - 1975 - I-Divergence Geometry of Probability Distributions.pdf:application/pdf},
}

@report{solomos_review_2008,
	title = {A review of the seismic hazard zonation in national building codes in the context of eurocode 8},
	institution = {{JRC} European Commission},
	type = {{EUR} 23563 {EN}-2008},
	author = {Solomos, George and Pinto, Artur and Dimova, Silvia},
	date = {2008},
	annotation = {Technical report},
}

@article{keller_nonparametric_2015,
	title = {Nonparametric Estimation of the Probability of Detection of Flaws in an Industrial Component, from Destructive and Nondestructive Testing Data, Using Approximate Bayesian Computation},
	volume = {35},
	doi = {10.1111/risa.12484},
	pages = {1595--1610},
	number = {9},
	journaltitle = {Risk Analysis},
	author = {Keller, Merlin and Popelin, Anne-Laure and Bousquet, Nicolas and Remy, Emmanuel},
	date = {2015-09},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/J72KH772/Keller et al. - 2015 - Nonparametric Estimation of the Probability of Det.pdf:application/pdf},
}

@article{zentner_fragility_2017,
	title = {Fragility analysis methods: Review of existing approaches and application},
	volume = {323},
	doi = {10.1016/j.nucengdes.2016.12.021},
	pages = {245--258},
	journaltitle = {Nuclear Engineering and Design},
	author = {Zentner, Irmela and Gündel, Max and Bonfils, Nicolas},
	date = {2017-11},
}

@thesis{lemaitre_reliability_2014,
	title = {Reliability sensitivity analysis},
	institution = {Université de Bordeaux},
	type = {phdthesis},
	author = {Lemaitre, Paul},
	date = {2014},
	annotation = {2014BORD0061},
}

@article{chu_bounds_1955,
	title = {On Bounds for the Normal Integral},
	volume = {42},
	doi = {10.2307/2333443},
	pages = {263--265},
	number = {1},
	journaltitle = {Biometrika},
	author = {Chu, John T.},
	date = {1955-06},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/96BUB436/Chu - 1955 - On Bounds for the Normal Integral.pdf:application/pdf},
}

@article{davis_leonhard_1959,
	title = {Leonhard Euler's Integral: A Historical Profile of the Gamma Function: In Memoriam: Milton Abramowitz},
	volume = {66},
	pages = {849--869},
	number = {10},
	journaltitle = {The American Mathematical Monthly},
	author = {Davis, Philip J.},
	date = {1959},
	note = {Publisher: [Taylor \& Francis, Ltd., Mathematical Association of America]},
}

@article{gautschi_elementary_1959,
	title = {Some Elementary Inequalities Relating to the Gamma and Incomplete Gamma Function},
	volume = {38},
	doi = {10.1002/sapm195938177},
	pages = {77--81},
	number = {1},
	journaltitle = {Journal of Mathematics and Physics},
	author = {Gautschi, Walter},
	date = {1959},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/BMMV26AT/Gautschi - 1959 - Some Elementary Inequalities Relating to the Gamma.pdf:application/pdf},
}

@article{trevlopoulos_parametric_2019,
	title = {Parametric models averaging for optimized non-parametric fragility curve estimation based on intensity measure data clustering},
	volume = {81},
	doi = {10.1016/j.strusafe.2019.05.002},
	pages = {101865},
	journaltitle = {Structural Safety},
	author = {Trevlopoulos, Konstantinos and Feau, Cyril and Zentner, Irmela},
	date = {2019},
	keywords = {Data clustering, Non-parametric curve, Optimization, Parametric models averaging, Seismic fragility curve},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/AP5BGMI5/Trevlopoulos et al. - 2019 - Parametric models averaging for optimized non-para.pdf:application/pdf},
}

@article{touboul_enhanced_2006,
	title = {Enhanced seismic criteria for piping},
	volume = {236},
	doi = {10.1016/j.nucengdes.2005.07.002},
	pages = {1--9},
	number = {1},
	journaltitle = {Nuclear Engineering and Design},
	author = {Touboul, Françoise and Blay, Nadine and Sollogoub, Pierre and Chapuliot, Stéphane},
	date = {2006},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/JMXYGZ39/Touboul et al. - 2006 - Enhanced seismic criteria for piping.pdf:application/pdf},
}

@article{rezaeian_simulation_2010,
	title = {Simulation of synthetic ground motions for specified earthquake and site characteristics},
	volume = {39},
	doi = {10.1002/eqe.997},
	pages = {1155--1180},
	number = {10},
	journaltitle = {Earthquake Engineering \& Structural Dynamics},
	shortjournal = {Earthq. En. St. Dyn},
	author = {Rezaeian, Sanaz and Der Kiureghian, Armen},
	date = {2010},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/F7SR8AIQ/Rezaeian et Der Kiureghian - 2010 - Simulation of synthetic ground motions for specifi.pdf:application/pdf},
}

@thesis{beylat_contribution_2020,
	title = {Contribution à l'étude du comportement dynamique aléatoire de structures libres et empilées sous séïsme},
	url = {https://theses.hal.science/tel-03159237},
	institution = {Université Clermont Auvergne [2017-2020]},
	type = {phdthesis},
	author = {Beylat, Delphine},
	date = {2020-10},
	note = {Issue: 2020CLFAC041},
	keywords = {Seismic, Analyse probabiliste, Basculements, Empilements, Fiabilité, Flexible structure, Free standing structure, Glissements, Probabilistic analysis, Reliability, Risk assessment studies, Rocking, Séismes, Sliding, Stacked structure, Structures flexibles, Structures libres, Sûreté},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/TT4XI4DA/Beylat - 2020 - Contribution à l'étude du comportement dynamique a.pdf:application/pdf},
}

@article{touboul_seismic_1999,
	title = {Seismic behaviour of piping systems with and without defects: experimental and numerical evaluations},
	volume = {192},
	doi = {10.1016/S0029-5493(99)00111-9},
	pages = {243--260},
	number = {2},
	journaltitle = {Nuclear Engineering and Design},
	author = {Touboul, Françoise and Sollogoub, Pierre and Blay, Nadine},
	date = {1999},
}

@article{haario_adaptive_2001,
	title = {An Adaptive Metropolis Algorithm},
	volume = {7},
	doi = {10.2307/3318737},
	pages = {223--242},
	number = {2},
	journaltitle = {Bernoulli},
	author = {Haario, Heikki and Saksman, Eero and Tamminen, Johanna},
	date = {2001-04},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/B8XG6A29/Haario et al. - 2001 - An Adaptive Metropolis Algorithm.pdf:application/pdf},
}

@article{bect_supermartingale_2019,
	title = {A supermartingale approach to Gaussian process based sequential design of experiments},
	volume = {25},
	doi = {10.3150/18-BEJ1074},
	pages = {2883--2919},
	number = {4},
	journaltitle = {Bernoulli},
	author = {Bect, Julien and Bachoc, François and Ginsbourger, David},
	date = {2019},
	note = {Publisher: Bernoulli Society for Mathematical Statistics and Probability},
	keywords = {Active learning, convergence, sequential design of experiments, stepwise uncertainty reduction, supermartingale, uncertainty functional},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/FHGLUKYX/Bect et al. - 2019 - A supermartingale approach to Gaussian process bas.pdf:application/pdf},
}

@book{kolmogorov_foundations_1933,
	edition = {2nd},
	title = {Foundations of the Theory of Probability},
	isbn = {0-486-82159-5},
	series = {Dover Books on Mathematics},
	publisher = {Dover Publications},
	author = {Kolmogorov, Andreï N.},
	date = {1933},
}

@article{kallioinen_detecting_2023,
	title = {Detecting and diagnosing prior and likelihood sensitivity with power-scaling},
	volume = {34},
	doi = {10.1007/s11222-023-10366-5},
	pages = {1573--1375},
	number = {57},
	journaltitle = {Statistics and Computing},
	author = {Kallioinen, Noa and Paananen, Topi and Bürkner, Paul-Christian},
	date = {2023},
	keywords = {Bayesian inference, model checking, prior data-conflict, variational Bayes},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/PMM6VYWF/Kallioinen et al. - 2023 - Detecting and diagnosing prior and likelihood sens.pdf:application/pdf},
}

@article{gelman_bayesian_2020,
	title = {Bayesian Workflow},
	doi = {10.48550/arXiv.2011.01808},
	journaltitle = {{arXiv}.2011.01808},
	author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and Bürkner, Paul-Christian and Modrák, Martin},
	date = {2020},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/ZV2R699M/Gelman et al. - 2020 - Bayesian Workflow.pdf:application/pdf},
}

@article{neyman_consistent_1948,
	title = {Consistent Estimates Based on Partially Consistent Observations},
	volume = {16},
	issn = {00129682, 14680262},
	doi = {10.2307/1914288},
	pages = {1--32},
	number = {1},
	journaltitle = {Econometrica},
	author = {Neyman, Jerzy and Scott, Elizabeth L.},
	date = {1948},
	note = {Publisher: [Wiley, Econometric Society]},
}

@book{renyi_foundations_1970,
	title = {Foundations of Probability},
	isbn = {978-0-486-46261-5},
	series = {Dover books on mathematics},
	publisher = {Dover Publications},
	author = {Renyi, Alfred},
	date = {1970},
}

@article{liang_mixtures_2008,
	title = {Mixtures of g Priors for Bayesian Variable Selection},
	volume = {103},
	doi = {10.1198/016214507000001337},
	pages = {410--423},
	number = {481},
	journaltitle = {Journal of the American Statistical Association},
	author = {Liang, Feng and Paulo, Rui and Molina, German and Clyde, Merlise A. and Berger, James O.},
	date = {2008},
	note = {Publisher: Taylor \& Francis},
}

@article{berger_robust_1990,
	title = {Robust Bayesian analysis: sensitivity to the prior},
	volume = {25},
	issn = {0378-3758},
	doi = {10.1016/0378-3758(90)90079-A},
	pages = {303--328},
	number = {3},
	journaltitle = {Journal of Statistical Planning and Inference},
	author = {Berger, James O.},
	date = {1990},
	file = {ScienceDirect Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/IMF2M5CV/Berger - 1990 - Robust Bayesian analysis sensitivity to the prior.pdf:application/pdf;ScienceDirect Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/TKN6M7BN/037837589090079A.html:text/html},
}

@article{perez_mcmc-based_2006,
	title = {{MCMC}-based local parametric sensitivity estimations},
	volume = {51},
	issn = {0167-9473},
	doi = {10.1016/j.csda.2005.09.005},
	pages = {823--835},
	number = {2},
	journaltitle = {Computational Statistics \& Data Analysis},
	author = {Pérez, Carlos J. and Martín, Jacinto and Rufo, María J.},
	date = {2006},
	keywords = {Bayesian decision theory, Bayesian inference, {MCMC}, Simulation},
}

@article{nott_checking_2020,
	title = {Checking for Prior-Data Conflict Using Prior-to-Posterior Divergences},
	volume = {35},
	doi = {10.1214/19-STS731},
	pages = {234--253},
	number = {2},
	journaltitle = {Statistical Science},
	author = {Nott, David J. and Wang, Xueou and Evans, Michael and Englert, Berthold-Georg},
	date = {2020},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Bayesian inference, model checking, prior data-conflict, variational Bayes},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/8T259JSS/Nott et al. - 2020 - Checking for Prior-Data Conflict Using Prior-to-Po.pdf:application/pdf},
}

@thesis{le_formal_2014,
	title = {The formal definition of reference priors under a general class of divergence},
	institution = {University of Missouri-Columbia},
	type = {phdthesis},
	author = {Le, Tri Minh},
	date = {2014},
	doi = {10.32469/10355/44185},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/WPSPNSJI/Le - 2014 - The formal definition of reference priors under a .pdf:application/pdf},
}

@article{castillo_bayesian_2015,
	title = {Bayesian linear regression with sparse priors},
	volume = {43},
	doi = {10.1214/15-AOS1334},
	pages = {1986--2018},
	number = {5},
	journaltitle = {The Annals of Statistics},
	author = {Castillo, Ismaël and Schmidt-Hieber, Johannes and van der Vaart, Aad},
	date = {2015},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Bayesian inference, Sparsity},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/WEV8PCFL/Castillo et al. - 2015 - Bayesian linear regression with sparse priors.pdf:application/pdf},
}

@article{spitzner_neutral-data_2011,
	title = {Neutral-data comparisons for Bayesian testing},
	volume = {6},
	doi = {10.1214/11-BA623},
	pages = {603--638},
	number = {4},
	journaltitle = {Bayesian Analysis},
	author = {Spitzner, Dan J.},
	date = {2011},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Analysis of variance, Bayes factors, Bayesian asymptotic-con-sistency, Bayesian hypothesis testing, model choice in high dimensions},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/XCHRVWSX/Spitzner - 2011 - Neutral-data comparisons for Bayesian testing.pdf:application/pdf},
}

@article{perez_expectedposterior_2002,
	title = {Expected‐posterior prior distributions for model selection},
	volume = {89},
	issn = {0006-3444},
	doi = {10.1093/biomet/89.3.491},
	pages = {491--512},
	number = {3},
	journaltitle = {Biometrika},
	author = {Pérez, José M. and Berger, James O.},
	date = {2002-08},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/27A69NTJ/Pérez et Berger - 2002 - Expected‐posterior prior distributions for model s.pdf:application/pdf},
}

@article{mure_optimal_2019,
	title = {Optimal compromise between incompatible conditional probability distributions, with application to Objective Bayesian Kriging},
	volume = {23},
	doi = {10.1051/ps/2018023},
	pages = {271--309},
	journaltitle = {{ESAIM}: {PS}},
	author = {Muré, Joseph},
	date = {2019},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/EPYZZ7WD/Muré - 2019 - Optimal compromise between incompatible conditiona.pdf:application/pdf},
}

@article{consonni_prior_2018,
	title = {Prior Distributions for Objective Bayesian Analysis},
	volume = {13},
	doi = {10.1214/18-BA1103},
	pages = {627--679},
	number = {2},
	journaltitle = {Bayesian Analysis},
	author = {Consonni, Guido and Fouskakis, Dimitris and Liseo, Brunero and Ntzoufras, Ioannis},
	date = {2018},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {criteria for model choice, high-dimensional model, model comparison, noninformative prior, objective Bayes, reference prior, Variable selection},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/59HT2A4Q/Consonni et al. - 2018 - Prior Distributions for Objective Bayesian Analysi.pdf:application/pdf},
}

@article{gelman_holes_2020,
	title = {Holes in Bayesian statistics},
	volume = {48},
	doi = {10.1088/1361-6471/abc3a5},
	pages = {014002},
	number = {1},
	journaltitle = {Journal of Physics G: Nuclear and Particle Physics},
	author = {Gelman, Andrew and Yao, Yuling},
	date = {2020-12},
	note = {Publisher: {IOP} Publishing},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/79VTN5YT/Gelman et Yao - 2020 - Holes in Bayesian statistics.pdf:application/pdf},
}

@article{mikkola_prior_2023,
	title = {Prior Knowledge Elicitation: The Past, Present, and Future},
	doi = {10.1214/23-BA1381},
	pages = {1--33},
	journaltitle = {Bayesian Analysis},
	author = {Mikkola, Petrus and Martin, Osvaldo A. and Chandramouli, Suyog and Hartmann, Marcelo and Pla, Oriol Abril and Thomas, Owen and Pesonen, Henri and Corander, Jukka and Vehtari, Aki and Kaski, Samuel and Bürkner, Paul-Christian and Klami, Arto},
	date = {2023},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Bayesian workflow, domain knowledge, informative prior, prior distribution, prior elicitation},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/YUSP4RHD/Mikkola et al. - 2023 - Prior Knowledge Elicitation The Past, Present, an.pdf:application/pdf},
}

@article{gupta_information_2009,
	title = {An information matrix prior for Bayesian Analysis in Generalized Linear Models with high dimensional data},
	volume = {19},
	issn = {10170405, 19968507},
	url = {https://www.jstor.org/stable/24308922},
	pages = {1641--1663},
	number = {4},
	journaltitle = {Statistica Sinica},
	author = {Gupta, Mayetri and Ibrahim, Joseph G.},
	date = {2009},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
}

@article{rubio_inference_2014,
	title = {Inference in Two-Piece Location-Scale Models with Jeffreys Priors},
	volume = {9},
	doi = {10.1214/13-BA849},
	pages = {1--22},
	number = {1},
	journaltitle = {Bayesian Analysis},
	author = {Rubio, Francisco J. and Steel, Mark F. J.},
	date = {2014},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Bayesian inference, noninformative prior, posterior existence, scale mixtures of normals, skewness},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/K85SZJUG/Rubio et Steel - 2014 - Inference in Two-Piece Location-Scale Models with .pdf:application/pdf},
}

@article{chen_properties_2008,
	title = {Properties and Implementation of Jeffreys’s Prior in Binomial Regression Models},
	volume = {103},
	doi = {10.1198/016214508000000779},
	pages = {1659--1664},
	number = {484},
	journaltitle = {Journal of the American Statistical Association},
	author = {Chen, Ming-Hui and Ibrahim, Joseph G. and Kim, Sungduk},
	date = {2008},
	note = {Publisher: Taylor \& Francis},
	file = {Version acceptée:/Users/antoinevanbiesbroeck/Zotero/storage/K9BJS7AQ/Chen et al. - 2008 - Properties and Implementation of Jeffreys’s Prior .pdf:application/pdf},
}

@article{chen_relationship_2006,
	title = {The relationship between the power prior and hierarchical models},
	volume = {1},
	doi = {10.1214/06-BA118},
	pages = {551--574},
	number = {3},
	journaltitle = {Bayesian Analysis},
	author = {Chen, Ming-Hui and Ibrahim, Joseph G.},
	date = {2006},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {generalized linear model, hierarchical model, historical data, power prior, prior elicitation, random effects model},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/JI8H5C8E/Chen et Ibrahim - 2006 - The relationship between the power prior and hiera.pdf:application/pdf},
}

@book{van_der_vaart_asymptotic_1992,
	edition = {1},
	title = {Asymptotic statistics},
	isbn = {978-0-511-80225-6},
	series = {Cambridge Series in Statistical and Probabilistic Mathematics},
	publisher = {Cambridge University Press},
	author = {van der Vaart, Aad},
	date = {1992},
}

@article{gu_jointly_2019,
	title = {Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection},
	volume = {14},
	doi = {10.1214/18-BA1133},
	pages = {857--885},
	number = {3},
	journaltitle = {Bayesian Analysis},
	author = {Gu, Mengyang},
	date = {2019},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {computer model, posterior propriety, reference prior, tail rate},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/CVB4RY97/Gu - 2019 - Jointly Robust Prior for Gaussian Stochastic Proce.pdf:application/pdf},
}

@incollection{berger_development_1992,
	location = {Oxford},
	title = {On the development of Reference Priors},
	isbn = {0-19-852266-5},
	pages = {35--60},
	booktitle = {Bayesian Statistics 4},
	publisher = {Oxford University Press},
	author = {Berger, James O. and Bernardo, José M.},
	date = {1992},
}

@book{cartan_cours_2007,
	edition = {2nd},
	title = {Cours de calcul différentiel},
	isbn = {978-2-7056-6702-3},
	series = {Sciences et techniques},
	publisher = {Hermann},
	author = {Cartan, Henri},
	date = {2007},
}

@book{zeidler_applied_2012,
	edition = {1st},
	title = {Applied functional Analysis},
	isbn = {978-1-4612-6913-7},
	series = {Applied Mathematical Sciences},
	publisher = {Springer New York, {NY}},
	author = {Zeidler, Eberhard},
	date = {2012},
	doi = {10.1007/978-1-4612-0821-1},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/AH9ZNR3N/Zeidler - 2012 - Applied functional Analysis.pdf:application/pdf},
}

@article{sobol_sensitivity_1993,
	title = {Sensitivity estimates for non linear mathematical models},
	volume = {1},
	pages = {407--414},
	journaltitle = {Mathematical Modeling and Computer Experiments},
	author = {Sobol', Ilya M.},
	date = {1993},
}

@article{da_veiga_global_2015,
	title = {Global sensitivity analysis with dependence measures},
	volume = {85},
	doi = {10.1080/00949655.2014.945932},
	pages = {1283--1305},
	number = {7},
	journaltitle = {Journal of Statistical Computation and Simulation},
	author = {Da Veiga, Sébastien},
	date = {2015},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/TB5RIECB/Da Veiga - 2015 - Global sensitivity analysis with dependence measur.pdf:application/pdf},
}

@article{jeffreys_invariant_1946,
	title = {An invariant form for the prior probability in estimation problems},
	volume = {186},
	pages = {453--461},
	number = {1007},
	journaltitle = {Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences},
	author = {Jeffreys, Harold},
	date = {1946-09},
	note = {Publisher: The Royal Society},
}

@article{clarke_reference_1997,
	title = {Reference Priors under the Chi-Squared Distance},
	volume = {59},
	issn = {0581572X},
	doi = {10.2307/25051152},
	pages = {215--231},
	number = {2},
	journaltitle = {Sankhyā: The Indian Journal of Statistics},
	author = {Clarke, Bertrand and Sun, Dongchu},
	date = {1997},
	note = {Publisher: Springer},
}

@inproceedings{gauchy_estimation_2022,
	title = {Estimation of seismic fragility curves by sequential design of experiments},
	url = {https://hal.science/hal-03588974v2},
	booktitle = {Proceedings des 53èmes Journées de Statistiques},
	publisher = {{SFDS}},
	author = {Gauchy, Clément and Feau, Cyril and Garnier, Josselin},
	date = {2022},
	note = {Place: Lyon, France},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/A9GQ8VXR/Gauchy et al. - 2022 - Estimation of seismic fragility curves by sequenti.pdf:application/pdf},
}

@article{clarke_information-theoretic_1990,
	title = {Information-theoretic asymptotics of Bayes methods},
	volume = {36},
	doi = {10.1109/18.54897},
	pages = {453--471},
	number = {3},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Clarke, Bertrand S. and Barron, Andrew R.},
	date = {1990},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/5PM4KAD4/Clarke et Barron - 1990 - Information-theoretic asymptotics of Bayes methods.pdf:application/pdf},
}

@incollection{chen_objective_2010,
	location = {New York, {NY}},
	title = {Objective Bayesian Inference with Applications},
	isbn = {978-1-4419-6944-6},
	pages = {31--68},
	booktitle = {Frontiers of Statistical Decision Making and Bayesian Analysis: In Honor of James O. Berger},
	publisher = {Springer New York},
	author = {Chen, Ming-Hui and Dey, Dipak K. and Müller, Peter and Sun, Dongchu and Ye, Keying},
	date = {2010},
	doi = {10.1007/978-1-4419-6944-6_2},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/JLQCZ5SK/Chen et al. - 2010 - Objective Bayesian Inference with Applications.pdf:application/pdf},
}

@article{liu_divergence_2014,
	title = {On Divergence Measures Leading to Jeffreys and Other Reference Priors},
	volume = {9},
	doi = {10.1214/14-BA862},
	pages = {331--370},
	number = {2},
	journaltitle = {Bayesian Analysis},
	author = {Liu, Ruitao and Chakrabarti, Arijit and Samanta, Tapas and Ghosh, Jayanta K. and Ghosh, Malay},
	date = {2014},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Jeffreys prior, reference prior, α-divergences},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/KAEWP5T2/Liu et al. - 2014 - On Divergence Measures Leading to Jeffreys and Oth.pdf:application/pdf},
}

@book{da_veiga_basics_2021,
	location = {Philadelphia, {PA}},
	edition = {1},
	title = {Basics and Trends in Sensitivity Analysis},
	isbn = {978-1-61197-668-7},
	series = {Computational Science \& Engineering},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Da Veiga, Sébastien and Gamboa, Fabrice and Iooss, Bertrand and Prieur, Clémentine},
	date = {2021},
	doi = {10.1137/1.9781611976694},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/JFVT384E/Da Veiga et al. - 2021 - Basics and Trends in Sensitivity Analysis.pdf:application/pdf},
}

@article{van_biesbroeck_properly_2024,
	title = {Properly constrained reference priors decay rates for efficient and robust posterior inference},
	doi = {10.48550/arXiv.2409.13041},
	journaltitle = {{arXiv}.2409.13041},
	author = {Van Biesbroeck, Antoine},
	date = {2024},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/BIKH8AAH/Van Biesbroeck - 2024 - Properly constrained reference priors decay rates .pdf:application/pdf},
}

@article{bousquet_discussion_2024,
	title = {Discussion of “Specifying prior distributions in reliability applications”: Towards new formal rules for informative prior elicitation?},
	volume = {40},
	doi = {10.1002/asmb.2794},
	pages = {92--102},
	number = {1},
	journaltitle = {Applied Stochastic Models in Business and Industry},
	author = {Bousquet, Nicolas},
	date = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asmb.2794},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/S62F5GW5/Bousquet - 2024 - Discussion of “Specifying prior distributions in r.pdf:application/pdf},
}

@article{taraldsen_conditional_2016,
	title = {Conditional probability and improper priors},
	volume = {45},
	doi = {10.1080/03610926.2014.935430},
	pages = {5007--5016},
	number = {17},
	journaltitle = {Communications in Statistics - Theory and Methods},
	author = {Taraldsen, Gunnar and Lindqvist, Bo Henry},
	date = {2016},
	note = {Publisher: Taylor \& Francis},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/8C43FRGW/Taraldsen et Lindqvist - 2016 - Conditional probability and improper priors.pdf:application/pdf},
}

@inproceedings{van_biesbroeck_influence_2023,
	title = {Influence of the choice of the seismic intensity measure on fragility curves estimation in a Bayesian framework based on reference prior},
	doi = {10.7712/120223.10327.19899},
	pages = {94--111},
	booktitle = {Proceedings of the 5th {UNCECOMP} Conference},
	author = {Van Biesbroeck, Antoine and Gauchy, Clément and Feau, Cyril and Garnier, Josselin},
	date = {2023-06},
	note = {Place: Athens, Greece},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/UFE5BY9Y/Van Biesbroeck et al. - 2023 - Influence of the choice of the seismic intensity m.pdf:application/pdf},
}

@article{van_biesbroeck_design_2024,
	title = {Design of experiment based on a low fidelity model for seismic fragility estimation},
	url = {https://hal.science/hal-04719458v1},
	journaltitle = {{ESAIM} : Proceedings and Surverys},
	author = {Van Biesbroeck, Antoine and Gauchy, Clément and Feau, Cyril and Garnier, Josselin},
	date = {2024},
	note = {Journal Abbreviation: {ESAIM}: {ProcS} 2024},
	file = {Texte intégral:/Users/antoinevanbiesbroeck/Zotero/storage/6KHVG3VP/Van Biesbroeck et al. - 2024 - Design of experiment based on a low fidelity model.pdf:application/pdf},
}

@misc{jaber_conformal_2024,
	title = {Conformal Approach To Gaussian Process Surrogate Evaluation With Coverage Guarantees},
	url = {http://arxiv.org/abs/2401.07733},
	doi = {10.48550/arXiv.2401.07733},
	abstract = {Gaussian processes ({GPs}) are a Bayesian machine learning approach widely used to construct surrogate models for the uncertainty quantification of computer simulation codes in industrial applications. It provides both a mean predictor and an estimate of the posterior prediction variance, the latter being used to produce Bayesian credibility intervals. Interpreting these intervals relies on the Gaussianity of the simulation model as well as the well-specification of the priors which are not always appropriate. We propose to address this issue with the help of conformal prediction. In the present work, a method for building adaptive cross-conformal prediction intervals is proposed by weighting the non-conformity score with the posterior standard deviation of the {GP}. The resulting conformal prediction intervals exhibit a level of adaptivity akin to Bayesian credibility sets and display a significant correlation with the surrogate model local approximation error, while being free from the underlying model assumptions and having frequentist coverage guarantees. These estimators can thus be used for evaluating the quality of a {GP} surrogate model and can assist a decision-maker in the choice of the best prior for the specific application of the {GP}. The performance of the method is illustrated through a panel of numerical examples based on various reference databases. Moreover, the potential applicability of the method is demonstrated in the context of surrogate modeling of an expensive-to-evaluate simulator of the clogging phenomenon in steam generators of nuclear reactors.},
	number = {{arXiv}:2401.07733},
	publisher = {{arXiv}},
	author = {Jaber, Edgar and Blot, Vincent and Brunel, Nicolas and Chabridon, Vincent and Remy, Emmanuel and Iooss, Bertrand and Lucor, Didier and Mougeot, Mathilde and Leite, Alessandro},
	urldate = {2025-03-11},
	date = {2024-01-15},
	eprinttype = {arxiv},
	eprint = {2401.07733 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/SWTRJDFF/Jaber et al. - 2024 - Conformal Approach To Gaussian Process Surrogate Evaluation With Coverage Guarantees.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/G93P9G6T/2401.html:text/html},
}

@article{acharki_robust_2023,
	title = {Robust prediction interval estimation for Gaussian processes by cross-validation method},
	volume = {178},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947322001773},
	doi = {10.1016/j.csda.2022.107597},
	abstract = {Probabilistic regression models typically use the Maximum Likelihood Estimation or Cross-Validation to fit parameters. These methods can give an advantage to the solutions that fit observations on average, but they do not pay attention to the coverage and the width of Prediction Intervals. A robust two-step approach is used to address the problem of adjusting and calibrating Prediction Intervals for Gaussian Processes Regression. First, the covariance hyperparameters are determined by a standard Cross-Validation or Maximum Likelihood Estimation method. A Leave-One-Out Coverage Probability is introduced as a metric to adjust the covariance hyperparameters and assess the optimal type {II} Coverage Probability to a nominal level. Then a relaxation method is applied to choose the hyperparameters that minimize the Wasserstein distance between the Gaussian distribution with the initial hyperparameters (obtained by Cross-Validation or Maximum Likelihood Estimation) and the proposed Gaussian distribution with the hyperparameters that achieve the desired Coverage Probability. The method gives Prediction Intervals with appropriate coverage probabilities and small widths.},
	pages = {107597},
	journaltitle = {Computational Statistics \& Data Analysis},
	shortjournal = {Computational Statistics \& Data Analysis},
	author = {Acharki, Naoufal and Bertoncello, Antoine and Garnier, Josselin},
	urldate = {2025-03-11},
	date = {2023-02-01},
	keywords = {Coverage probability, Cross-validation, Gaussian processes, Prediction intervals},
	file = {ScienceDirect Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/NTVH4PJD/S0167947322001773.html:text/html;Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/D3Q2IZH2/Acharki et al. - 2023 - Robust prediction interval estimation for Gaussian processes by cross-validation method.pdf:application/pdf},
}

@misc{bousquet_covariance_2025,
	title = {Covariance constraints for stochastic inverse problems of computer models},
	url = {http://arxiv.org/abs/1806.03440},
	doi = {10.48550/arXiv.1806.03440},
	abstract = {Stochastic inverse problems considered in this article consist of estimating the probability distributions of intrinsically random inputs of computer models. These estimations are based on observable outputs affected by model noise, and such problems are increasingly examined in parametric Bayesian contexts where the parameters of the targeted input distributions are affected by epistemic uncertainties. With the aim of improving the meaningfulness of solutions found by statistical algorithms -- in the sense that forward simulations based on such solutions must lead to relevant observables -- we derive new prior constraints using the principles of global sensitivity analysis and information theory. Primarily formalized as constraints on covariances in Gaussian linear or linearizable situations, they reflect the idea that the solution should explain most of the observable uncertainty, while the model noise remains a secondary factor of this uncertainty. Simulated experiments highlight that, when injected into stochastic inversion algorithms, these constraints can indeed limit the influence of model noise on the result. They provide hope for future extensions in more general frameworks, for example through the use of linear Gaussian mixtures.},
	number = {{arXiv}:1806.03440},
	publisher = {{arXiv}},
	author = {Bousquet, Nicolas and Blazère, Mélanie and Cerbelaud, Thomas},
	urldate = {2025-03-11},
	date = {2025-01-22},
	eprinttype = {arxiv},
	eprint = {1806.03440 [math]},
	keywords = {Mathematics - Statistics Theory, Statistics - Statistics Theory},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/MG7FXTKA/Bousquet et al. - 2025 - Covariance constraints for stochastic inverse problems of computer models.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/HHCKYPGY/1806.html:text/html},
}

@report{berger_development_1991,
	title = {On the development of the reference prior method},
	url = {https://www2.stat.duke.edu/~berger/papers/ref-development.pdf},
	number = {91-15C},
	institution = {Purdue University},
	author = {Berger, James O. and Bernardo, José M.},
	urldate = {2025-03-11},
	date = {1991},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/SHH6XGF7/ref-development.pdf:application/pdf},
}

@thesis{piera-martinez_modelisation_2008,
	title = {Modélisation des comportements extrêmes en ingénierie},
	url = {https://theses.hal.science/tel-00338076},
	abstract = {La complexité d'un système et les approximations de modélisation qui en résultent, le caractère aléatoire des perturbations externes ainsi que la dispersion des paramètres de conception autour de leur valeur nominale sont autant de raisons qui amènent à remettre en cause les approches déterministes qui supposent une connaissance parfaite du système et de son environnement. La n´ecessité de concevoir des systèmes robustes nous conduit à élaborer des modèles statistiques qui permettent de gérer les incertitudes, et en particulier l'apparition de valeurs extrêmes à la sortie des systèmes. La modélisation des valeurs extrêmes et la protection d'un système vis-à-vis de ces évènements revêt un intérêt particulier, puisque ces valeurs extrêmes peuvent correspondre à des violations du cahier des charges, voire à des destructions du système. L'objectif de ce mémoire est de mettre en place des outils pour étudier les performances d'un dispositif lorsqu'il est sollicité à la limite du fonctionnement normalement prévu. Une valeur extrême est en général un évènement rare qui nécessite a priori de faire un grand nombre d'expériences avant d'être observé. Cependant, de telles expériences, ou les simulations qui sont de plus en plus utilisées pour les remplacer, sont souvent coûteuses. Il est donc souhaitable de caractériser les valeurs extrêmes à partir d'un petit nombre d'expériences ou de simulations. Concrètement, nous étudions la modélisation des queues de probabilité, l'estimation d'une faible probabilité de défaillance et l'estimation du pire cas de fonctionnement d'un système.},
	institution = {Université Paris Sud - Paris {XI}},
	type = {phdthesis},
	author = {Piera-Martinez, Miguel},
	urldate = {2025-03-11},
	date = {2008-09-29},
	langid = {french},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/ZUPMZT28/Piera-Martinez - 2008 - Modélisation des comportements extrêmes en ingénierie.pdf:application/pdf},
}

@thesis{chevalier_fast_2013,
	title = {Fast uncertainty reduction strategies relying on Gaussian process models},
	url = {https://theses.hal.science/tel-00879082},
	abstract = {This work deals with sequential and batch-sequential evaluation strategies of real-valued functions under limited evaluation budget, using Gaussian process models. Optimal Stepwise Uncertainty Reduction ({SUR}) strategies are investigated for two diff erent problems, motivated by real test cases in nuclear safety. First we consider the problem of identifying the excursion set above a given threshold T of a real-valued function f. Then we study the question of finding the set of "safe controlled con gurations", i.e. the set of controlled inputs where the function remains below T, whatever the value of some others non-controlled inputs. New {SUR} strategies are presented, together with effi cient procedures and formulas to compute and use them in real-world applications. The use of fast formulas to recalculate quickly the posterior mean or covariance function of a Gaussian process (referred to as the "kriging update formulas") does not only provide substantial computational savings. It is also one of the key tools to derive closed-form formulas enabling a practical use of computationally-intensive sampling strategies. A contribution in batch-sequential optimization (with the multi-points Expected Improvement) is also presented.},
	institution = {Universität Bern},
	type = {phdthesis},
	author = {Chevalier, Clément},
	urldate = {2025-03-11},
	date = {2013-09-18},
	langid = {english},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/PMGKFBZW/Chevalier - 2013 - Fast uncertainty reduction strategies relying on Gaussian process models.pdf:application/pdf},
}

@article{bodnar_analytical_2014,
	title = {Analytical derivation of the reference prior by sequential maximization of Shannon's mutual information in the multi-group parameter case},
	volume = {147},
	issn = {0378-3758},
	url = {https://www.sciencedirect.com/science/article/pii/S0378375813002802},
	doi = {10.1016/j.jspi.2013.11.003},
	abstract = {We provide an analytical derivation of a non-informative prior by sequential maximization of Shannon's mutual information in the multi-group parameter case assuming reasonable regularity conditions. We show that the derived prior coincides with the reference prior proposed by Berger and Bernardo, and that it can be considered as a useful alternative expression for the calculation of the reference prior. In using this expression we discuss the conditions under which an improper reference prior can be uniquely defined, i.e. when it does not depend on the particular choice of nested sequences of compact subsets of the parameter space needed for its construction. We also present the conditions under which the reference prior coincides with Jeffreys' prior.},
	pages = {106--116},
	journaltitle = {Journal of Statistical Planning and Inference},
	shortjournal = {Journal of Statistical Planning and Inference},
	author = {Bodnar, Olha and Elster, Clemens},
	urldate = {2025-03-11},
	date = {2014-04-01},
	keywords = {Reference prior, Shannon's mutual information},
	file = {ScienceDirect Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/WZN8QB2H/Bodnar et Elster - 2014 - Analytical derivation of the reference prior by sequential maximization of Shannon's mutual informat.pdf:application/pdf},
}

@article{kyprioti_adaptive_2020,
	title = {Adaptive design of experiments for global Kriging metamodeling through cross-validation information},
	volume = {62},
	issn = {1615-1488},
	url = {https://doi.org/10.1007/s00158-020-02543-1},
	doi = {10.1007/s00158-020-02543-1},
	abstract = {This paper discusses a new sequential adaptive design of experiments ({DoE}) approach for global Kriging metamodeling applications. The sequential implementation is established by using the current metamodel, formulated based on the existing experiments, to guide the selection of the optimal new experiment(s). The score function, defining the {DoE} objective, combines two components: (1) the metamodel prediction variability, expressed through the predictive variance, and (2) the metamodel bias, approximated through the leave-one-out cross validation ({LOOCV}) error. The latter is used as a weighting factor to extend traditional {DoE} approaches that focus solely on the metamodel prediction variability. Two such approaches are considered here, adopting either the integrated mean squared error or the maximum mean squared error as the basic component of the score function. The incorporation of bias information as weighting within these well-established approaches facilitates a direct extension of their respective computational workflows, making the proposed implementation attractive from computational perspective. An efficient optimization scheme for identification of the next experiment, as well as the balancing of exploration and exploitation between the two components of the score function, are also discussed. The incorporation of {LOOCV} weightings is shown to be highly beneficial in a total of six analytical and engineering examples. Furthermore, these examples demonstrate that for {DoE} approaches which use {LOOCV} information as weights, it is preferable to update the predictive variance to explicitly consider the impact of the new experiment, rather than relying strictly on the current metamodel variance.},
	pages = {1135--1157},
	number = {3},
	journaltitle = {Structural and Multidisciplinary Optimization},
	shortjournal = {Struct Multidisc Optim},
	author = {Kyprioti, Aikaterini P. and Zhang, Jize and Taflanidis, Alexandros A.},
	urldate = {2025-03-11},
	date = {2020-09-01},
	langid = {english},
	keywords = {Adaptive design of experiments ({DoE}), Kriging, Leave-one-out cross-validation weights, Sequential {DoE}, Weighted integrated mean squared error, Weighted maximum mean squared error},
}

@article{van_der_vaart_vitesses_2004,
	title = {Vitesses de convergence de mesures a posteriori},
	volume = {145},
	url = {http://www.numdam.org/item/JSFS_2004__145_1_7_0/},
	pages = {7--30},
	number = {1},
	journaltitle = {Journal de la Société française de statistique},
	author = {van der Vaart, Aad},
	date = {2004},
	langid = {french},
	note = {Publisher: Société française de statistique},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/WB6CR393/Vitesses de convergence de mesures a posteriori.pdf:application/pdf},
}

@report{zhu_information_1995,
	title = {Information geometric measurements of generalisation},
	url = {https://publications.aston.ac.uk/id/eprint/507/},
	abstract = {Neural networks can be regarded as statistical models, and can be analysed in a Bayesian framework. Generalisation is measured by the performance on independent test data drawn from the same distribution as the training data. Such performance can be quantified by the posterior average of the information divergence between the true and the model distributions. Averaging over the Bayesian posterior guarantees internal coherence; Using information divergence guarantees invariance with respect to representation. The theory generalises the least mean squares theory for linear Gaussian models to general problems of statistical estimation. The main results are: (1){\textasciitilde}the ideal optimal estimate is always given by average over the posterior; (2){\textasciitilde}the optimal estimate within a computational model is given by the projection of the ideal estimate to the model. This incidentally shows some currently popular methods dealing with hyperpriors are in general unnecessary and misleading. The extension of information divergence to positive normalisable measures reveals a remarkable relation between the {\textless}span class='mathrm'{\textgreater}dlt{\textless}/span{\textgreater} dual affine geometry of statistical manifolds and the geometry of the dual pair of Banach spaces {\textless}span class='mathrm'{\textgreater}Ld{\textless}/span{\textgreater} and {\textless}span class='mathrm'{\textgreater}Ldd{\textless}/span{\textgreater}. It therefore offers conceptual simplification to information geometry. The general conclusion on the issue of evaluating neural network learning rules and other statistical inference methods is that such evaluations are only meaningful under three assumptions: The prior {\textless}span class='mathrm'{\textgreater}P(p){\textless}/span{\textgreater}, describing the environment of all the problems; the divergence {\textless}span class='mathrm'{\textgreater}Dd{\textless}/span{\textgreater}, specifying the requirement of the task; and the model {\textless}span class='mathrm'{\textgreater}Q{\textless}/span{\textgreater}, specifying available computing resources.},
	number = {{NCRG}/4350},
	institution = {Neural Computing Research Group},
	type = {Monograph},
	author = {Zhu, Huaiyu and Rohwer, Richard},
	urldate = {2025-03-11},
	date = {1995},
	langid = {british},
	note = {Place: Birmingham, {UK}
Num Pages: 403709
Publisher: Aston University},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/KSFL2VXP/Zhu et Rohwer - 1995 - Information geometric measurements of generalisation.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/XFWRXQ4K/507.html:text/html},
}

@article{marrel_statistical_2021,
	title = {Statistical developments for target and conditional sensitivity analysis: application on safety studies for nuclear reactor},
	volume = {214},
	url = {https://hal.science/hal-02541142},
	doi = {10.1016/j.ress.2021.107711},
	shorttitle = {Statistical developments for target and conditional sensitivity analysis},
	abstract = {In the framework of uncertainty treatment in numerical simulation, Global sensitivity analysis ({GSA}) aims at determining (qualitatively or quantitatively) how the variability of the uncertain inputs affects the model output. However, from reliability and risk management perspectives, {GSA} might be insufficient to capture the influence of the inputs on a restricted domain of the output (e.g., critical event).
To remedy this, we define target ({TSA}) and conditional sensitivity analysis ({CSA}) to measure respectively the influence of the inputs on the occurrence of the critical event, and on the output within the critical domain. From existing {GSA} measures, new operational tools are proposed for {TSA} and {CSA}, based on Sobol’ index and Hilbert–Schmidt Independence Criterion ({HSIC}). Moreover, to cope with the loss of information (especially when the critical domain is of low probability) and reduce the variability of estimators, transformation of the output using weight functions is also proposed.
These new {TSA} and {CSA} tools are tested and compared on analytical examples. The efficiency of {HSIC}-based indices clearly appear, as well as the relevancy of smooth relaxation. Finally, these latter indices are applied and interpreted on a nuclear engineering use case simulating a severe accidental scenario on a pressurized water reactor.},
	pages = {107711},
	journaltitle = {Reliability Engineering and System Safety},
	author = {Marrel, Amandine and Chabridon, Vincent},
	urldate = {2025-03-13},
	date = {2021},
	note = {Publisher: Elsevier},
	keywords = {Hilbert-Schmidt independence criterion, Reliability analysis, Sensitivity analysis, Sobol indices},
	file = {HAL PDF Full Text:/Users/antoinevanbiesbroeck/Zotero/storage/S6K9BMX9/Marrel et Chabridon - 2021 - Statistical developments for target and conditional sensitivity analysis application on safety stud.pdf:application/pdf},
}

@article{ghosh_general_2011,
	title = {A general divergence criterion for prior selection},
	volume = {63},
	issn = {1572-9052},
	url = {https://doi.org/10.1007/s10463-009-0226-4},
	doi = {10.1007/s10463-009-0226-4},
	abstract = {The paper revisits the problem of selection of priors for regular one-parameter family of distributions. The goal is to find some “objective” or “default” prior by approximate maximization of the distance between the prior and the posterior under a general divergence criterion as introduced by Amari (Ann Stat 10:357–387, 1982) and Cressie and Read (J R Stat Soc Ser B 46:440–464, 1984). The maximization is based on an asymptotic expansion of this distance. The Kullback–Leibler, Bhattacharyya–Hellinger and Chi-square divergence are special cases of this general divergence criterion. It is shown that with the exception of one particular case, namely the Chi-square divergence, the general divergence criterion yields Jeffreys’ prior. For the Chi-square divergence, we obtain a prior different from that of Jeffreys and also from that of Clarke and Sun (Sankhya Ser A 59:215–231, 1997).},
	pages = {43--58},
	number = {1},
	journaltitle = {Annals of the Institute of Statistical Mathematics},
	shortjournal = {Ann Inst Stat Math},
	author = {Ghosh, Malay and Mergel, Victor and Liu, Ruitao},
	urldate = {2025-03-13},
	date = {2011-02-01},
	langid = {english},
	keywords = {Chi-square distance, Fisher information number, Jeffreys’ prior},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/QWFJQW49/Ghosh et al. - 2011 - A general divergence criterion for prior selection.pdf:application/pdf},
}

@article{meng_multi-fidelity_2021,
	title = {Multi-fidelity Bayesian neural networks: Algorithms and applications},
	volume = {438},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999121002564},
	doi = {10.1016/j.jcp.2021.110361},
	shorttitle = {Multi-fidelity Bayesian neural networks},
	abstract = {We propose a new class of Bayesian neural networks ({BNNs}) that can be trained using noisy data of variable fidelity, and we apply them to learn function approximations as well as to solve inverse problems based on partial differential equations ({PDEs}). These multi-fidelity {BNNs} consist of three neural networks: The first is a fully connected neural network, which is trained following the maximum a posteriori probability ({MAP}) method to fit the low-fidelity data; the second is a Bayesian neural network employed to capture the cross-correlation with uncertainty quantification between the low- and high-fidelity data; and the last one is the physics-informed neural network, which encodes the physical laws described by {PDEs}. For the training of the last two neural networks, we first employ the mean-field variational inference ({VI}) to maximize the evidence lower bound ({ELBO}) to obtain informative prior distributions for the hyperparameters in the {BNNs}, and subsequently we use the Hamiltonian Monte Carlo ({HMC}) method to estimate accurately the posterior distributions for the corresponding hyperparameters. We demonstrate the accuracy of the present method using synthetic data as well as real measurements. Specifically, we first approximate a one- and four-dimensional function, and then infer the reaction rates in one- and two-dimensional diffusion-reaction systems. Moreover, we infer the sea surface temperature ({SST}) in the Massachusetts and Cape Cod Bays using satellite images and in-situ measurements. Taken together, our results demonstrate that the present method can capture both linear and nonlinear correlation between the low- and high-fidelity data adaptively, identify unknown parameters in {PDEs}, and quantify uncertainties in predictions, given a few scattered noisy high-fidelity data. Finally, we demonstrate that we can effectively and efficiently reduce the uncertainties and hence enhance the prediction accuracy with an active learning approach, using as examples a specific one-dimensional function approximation and an inverse {PDE} problem.},
	pages = {110361},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Meng, Xuhui and Babaee, Hessam and Karniadakis, George Em},
	urldate = {2025-03-13},
	date = {2021-08-01},
	keywords = {Active learning, Hamiltonian Monte Carlo, Nonlinear correlation, Physics-informed neural networks, Satellite data, Uncertainty quantification},
	file = {ScienceDirect Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/P2NLECUW/S0021999121002564.html:text/html;Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/PX2U5ULZ/Meng et al. - 2021 - Multi-fidelity Bayesian neural networks Algorithms and applications.pdf:application/pdf},
}

@inproceedings{watson_latent_2021,
	title = {Latent Derivative Bayesian Last Layer Networks},
	url = {https://proceedings.mlr.press/v130/watson21a.html},
	abstract = {Bayesian neural networks ({BNN}) are powerful parametric models for nonlinear regression with uncertainty quantification. However, the approximate inference techniques for weight space priors suffer from several drawbacks. The ‘Bayesian last layer’ ({BLL}) is an alternative {BNN} approach that learns the feature space for an exact Bayesian linear model with explicit predictive distributions. However, its predictions outside of the data distribution ({OOD}) are typically overconfident, as the marginal likelihood objective results in a learned feature space that overfits to the data. We overcome this weakness by introducing a functional prior on the model’s derivatives w.r.t. the inputs. Treating these Jacobians as latent variables, we incorporate the prior into the objective to influence the smoothness and diversity of the features, which enables greater predictive uncertainty. For the {BLL}, the Jacobians can be computed directly using forward mode automatic differentiation, and the distribution over Jacobians may be obtained in closed-form. We demonstrate this method enhances the {BLL} to Gaussian process-like performance on tasks where calibrated uncertainty is critical: {OOD} regression, Bayesian optimization and active learning, which include high-dimensional real-world datasets.},
	eventtitle = {International Conference on Artificial Intelligence and Statistics},
	pages = {1198--1206},
	booktitle = {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Watson, Joe and Lin, Jihao Andreas and Klink, Pascal and Pajarinen, Joni and Peters, Jan},
	urldate = {2025-03-13},
	date = {2021-03-18},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/75U3DKXT/Watson et al. - 2021 - Latent Derivative Bayesian Last Layer Networks.pdf:application/pdf;Supplementary PDF:/Users/antoinevanbiesbroeck/Zotero/storage/77DUSL4L/Watson et al. - 2021 - Latent Derivative Bayesian Last Layer Networks.pdf:application/pdf},
}

@article{fiedler_improved_2023,
	title = {Improved Uncertainty Quantification for Neural Networks With Bayesian Last Layer},
	volume = {11},
	doi = {10.1109/ACCESS.2023.3329685},
	pages = {123149--123160},
	journaltitle = {{IEEE} Access},
	author = {Fiedler, Felix and Lucia, Sergio},
	date = {2023},
	keywords = {Artificial neural networks, Bayes methods, Bayesian last layer, bayesian neural network, Extrapolation, Machine learning, Optimization, Probabilistic logic, Training, Uncertainty, uncertainty quantification},
}

@article{wuertz_generalized_nodate,
	title = {Generalized Lambda Distribution},
	author = {Wuertz, Diethelm and Chalabi, Yohan},
	langid = {english},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/MWKUVZ2J/Wuertz et Chalabi - Generalized Lambda Distribution.pdf:application/pdf},
}

@thesis{sarazin_analyse_2021,
	title = {Analyse de sensibilité fiabiliste en présence d'incertitudes épistémiques introduites par les données d'apprentissage},
	rights = {Licence Etalab},
	url = {https://theses.fr/2021ESAE0018},
	abstract = {Dans le contexte d'une analyse de fiabilité, pour évaluer la position de retombée d'un étage de lanceur de satellite et pour estimer le risque de défaillance associé, il est souvent nécessaire d'utiliser un code de simulation numérique dont les entrées sont des mesures issues de systèmes embarqués. La méconnaissance des incertitudes affectant ces entrées mesurées peut avoir un impact considérable sur la qualité de l'estimation du risque de défaillance. Ces travaux de thèse ont deux objectifs principaux :     - Implémenter un algorithme permettant d'acquérir le maximum de connaissances sur la distribution des entrées (sachant que la seule matière première est un jeu de données de petite taille) avant d'utiliser le résultat de cette apprentissage pour quantifier le risque de défaillance.    - Effectuer une analyse de sensibilité permettant de comprendre quelles sont les variables d'entrée ou bien les motifs de dépendance en entrée qui jouent un rôle clé dans le processus d'estimation du risque.},
	institution = {Toulouse, {ISAE}},
	type = {These de doctorat},
	author = {Sarazin, Gabriel},
	editora = {Morio, Jérôme and Lagnoux, Agnès},
	editoratype = {collaborator},
	urldate = {2025-03-13},
	date = {2021-05-27},
	keywords = {Aleatory and epistemic uncertainties, Analyse de sensibilité, Copula theory, Estimation de probabilités d'évènements rares, Incertitudes aléatoires et épistémiques, Inferential statistics, Méthodes de simulation de Monte-Carlo, Modèles mathématiques, Monte Carlo simulation methods, Monte-Carlo, Méthode de, Rare-Event probability estimation, Sensibilité, Théorie de la (mathématiques), Sensitivity analysis, Statistique inférentielle, Théorie des copules},
}

@inproceedings{zhu_use_2022,
	location = {Hannover, Germany},
	title = {Use of generalized lambda models for seismic fragility analysis},
	url = {https://hal.science/hal-03788059},
	booktitle = {8th International Symposium on Reliability Engineering and Risk Management ({ISRERM})},
	author = {Zhu, Xujia and Broccardo, Marco and Sudret, Bruno},
	urldate = {2025-03-13},
	date = {2022-09},
	file = {HAL PDF Full Text:/Users/antoinevanbiesbroeck/Zotero/storage/5R3UMJAV/Zhu et al. - 2022 - Use of generalized lambda models for seismic fragility analysis.pdf:application/pdf},
}

@thesis{zhu_surrogate_2023,
	title = {Surrogate Modeling for Stochastic Simulators Using Statistical Approaches},
	rights = {http://rightsstatements.org/page/{InC}-{NC}/1.0/},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/604116},
	abstract = {Nowadays, more and more complex interdependent infrastructures and networks are developed in engineering. The design and maintenance of such systems increasingly call for advanced computational models to optimize their performance and assess their reliability under various operational conditions. Unlike many conventional simulators that are deterministic, stochastic simulators feature intrinsic stochasticity. More precisely, they produce different results when run multiple times with a given set of input parameters. Due to this random nature, repeated model evaluations of the stochastic model with the same input value, called replications, are necessary to fully characterize the probability distribution of the associated model response.   For the purpose of optimization or uncertainty quantification (e.g., uncertainty propagation or sensitivity analysis), computational models typically need to be evaluated a large number of times. The additional layer of randomness due to the intrinsic stochasticity of stochastic simulators makes it even more computationally demanding to perform these complex analyses. A common practice to alleviate the prohibitive cost associated with expensive simulators is to build surrogate models, which behave similarly to the original model but are much cheaper to evaluate.  Contrary to the deterministic case, surrogate modeling of stochastic simulators has only emerged in the past decade. The main challenge in this field is that one model evaluation yields only a single realization of the random model response associated with the given input value. In other words, one run of a stochastic simulator provides proportionally much less information than that of a deterministic one.   This thesis focuses on developing efficient and accurate surrogate models to emulate the response distribution of stochastic simulators, combining statistical methods with state-of-the-art deterministic surrogate modeling techniques.   To this end, we propose two new approaches: the generalized lambda model ({GLaM}) and the stochastic polynomial chaos expansion ({SPCE}). The first one capitalizes on the use of the generalized lambda distribution to characterize the random nature of the simulator response. The distribution parameters are functions of the input variables and are represented by polynomial chaos expansions ({PCEs}). We explore replication-based methods to build {GLaMs} and improve their performance by an additional joint optimization of the overall likelihood function. We further elaborate this idea and develop a new method that does not require replications. Using this surrogate, we investigate sensitivity analysis for stochastic simulators.  The second class of stochastic surrogates, {SPCE}, overcomes the main shortcoming of {GLaM}, which is unable to represent multimodal distributions. In this more versatile stochastic emulator, we extend {PCE} by introducing an artificial latent variable to the expansion and an additive noise variable to mimic the intrinsic stochasticity of the simulator. We also propose an adaptive algorithm to construct the surrogate model without the need for replications.   For both stochastic surrogate models, we investigate basic theoretical properties of the primary estimation method. Analytical examples and engineering applications, including wind turbine design and seismic fragility analysis, are used to validate and illustrate the performance of the new approaches. Furthermore, these engineering case studies provide valuable insights into the applicability of the developed framework to real-world industrial problems.},
	institution = {{ETH} Zurich},
	type = {Doctoral Thesis},
	author = {Zhu, Xujia},
	urldate = {2025-03-13},
	date = {2023},
	langid = {english},
	doi = {10.3929/ethz-b-000604116},
	note = {Accepted: 2023-03-21T14:04:56Z},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/S58G25AZ/Zhu - 2023 - Surrogate Modeling for Stochastic Simulators Using Statistical Approaches.pdf:application/pdf},
}

@article{burkner_fully_2023,
	title = {A fully Bayesian sparse polynomial chaos expansion approach with joint priors on the coefficients and global selection of terms},
	volume = {488},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999123003054},
	doi = {10.1016/j.jcp.2023.112210},
	abstract = {Polynomial chaos expansion ({PCE}) is a versatile tool widely used in uncertainty quantification and machine learning, but its successful application depends strongly on the accuracy and reliability of the resulting {PCE}-based response surface. High accuracy typically requires high polynomial degrees, demanding many training points especially in high-dimensional problems through the curse of dimensionality. So-called sparse {PCE} concepts work with a much smaller selection of basis polynomials compared to conventional {PCE} approaches and can overcome the curse of dimensionality very efficiently, but have to pay specific attention to their strategies of choosing training points. Furthermore, the approximation error resembles an uncertainty that most existing {PCE}-based methods do not estimate. In this study, we develop and evaluate a fully Bayesian approach to establish the {PCE} representation via joint shrinkage priors and Markov chain Monte Carlo. The suggested Bayesian {PCE} model directly aims to solve the two challenges named above: achieving a sparse {PCE} representation and estimating uncertainty of the {PCE} itself. The embedded Bayesian regularizing via the joint shrinkage prior allows using higher polynomial degrees for given training points due to its ability to handle underdetermined situations, where the number of considered {PCE} coefficients could be much larger than the number of available training points. We also explore multiple variable selection methods to construct sparse {PCE} expansions based on the established Bayesian representations, while globally selecting the most meaningful orthonormal polynomials given the available training data. We demonstrate the advantages of our Bayesian {PCE} and the corresponding sparsity-inducing methods on several benchmarks.},
	pages = {112210},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Bürkner, Paul-Christian and Kröker, Ilja and Oladyshkin, Sergey and Nowak, Wolfgang},
	urldate = {2025-03-13},
	date = {2023-09-01},
	keywords = {Bayesian inference, Polynomial chaos expansion, Shrinkage priors, Surrogate modeling, Uncertainty quantification, Variable selection},
	file = {ScienceDirect Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/Q534U8RE/Bürkner et al. - 2023 - A fully Bayesian sparse polynomial chaos expansion approach with joint priors on the coefficients an.pdf:application/pdf;ScienceDirect Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/2PIQF986/S0021999123003054.html:text/html},
}

@article{shao_bayesian_2017,
	title = {Bayesian sparse polynomial chaos expansion for global sensitivity analysis},
	volume = {318},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782516307010},
	doi = {10.1016/j.cma.2017.01.033},
	abstract = {Polynomial chaos expansions are frequently used by engineers and modellers for uncertainty and sensitivity analyses of computer models. They allow representing the input/output relations of computer models. Usually only a few terms are really relevant in such a representation. It is a challenge to infer the best sparse polynomial chaos expansion of a given model input/output data set. In the present article, sparse polynomial chaos expansions are investigated for global sensitivity analysis of computer model responses. A new Bayesian approach is proposed to perform this task, based on the Kashyap information criterion for model selection. The efficiency of the proposed algorithm is assessed on several benchmarks before applying the algorithm to identify the most relevant inputs of a double-diffusive convection model.},
	pages = {474--496},
	journaltitle = {Computer Methods in Applied Mechanics and Engineering},
	shortjournal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Shao, Qian and Younes, Anis and Fahs, Marwan and Mara, Thierry A.},
	urldate = {2025-03-13},
	date = {2017-05-01},
	keywords = {Bayesian model averaging, Double-diffusive convection, Global sensitivity analysis, Kashyap information criterion, Sobol’ indices, Sparse polynomial chaos expansion},
	file = {ScienceDirect Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/5X9Q284P/Shao et al. - 2017 - Bayesian sparse polynomial chaos expansion for global sensitivity analysis.pdf:application/pdf},
}

@article{bhattacharyya_global_2020,
	title = {Global sensitivity analysis: A Bayesian learning based polynomial chaos approach},
	volume = {415},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120303132},
	doi = {10.1016/j.jcp.2020.109539},
	shorttitle = {Global sensitivity analysis},
	abstract = {A novel sparse polynomial chaos expansion ({PCE}) is proposed in this paper for global sensitivity analysis ({GSA}). The proposed model combines variational Bayesian ({VB}) inference and automatic relevance determination ({ARD}) with the {PCE} model. The {VB} inference is utilized to compute the {PCE} coefficients. The {PCE} coefficients are obtained through a simple optimization procedure in the {VB} framework. On the other hand, the curse of dimensionality issue of {PCE} model is tackled using the {ARD} which reduces the number of polynomial bases significantly. The applicability of the proposed approach is illustrated by performing {GSA} on five numerical examples. The results show that the proposed approach outperforms a similar state-of-art surrogate model in obtaining an accurate sensitivity index using limited number of model evaluations. For all the examples, the {PCE} models are highly sparse, which require very few polynomial bases to assess an accurate sensitivity index.},
	pages = {109539},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Bhattacharyya, Biswarup},
	urldate = {2025-03-13},
	date = {2020-08-15},
	keywords = {Automatic relevance determination, Bayesian approach, Global sensitivity analysis, Sobol' indices, Sparse polynomial chaos expansion},
	file = {ScienceDirect Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/LXYIBDTJ/Bhattacharyya - 2020 - Global sensitivity analysis A Bayesian learning based polynomial chaos approach.pdf:application/pdf;ScienceDirect Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/TGFJJTI5/S0021999120303132.html:text/html},
}

@thesis{stenger_optimal_2020,
	title = {Optimal uncertainty quantification of a risk measurement from a computer code},
	url = {http://thesesups.ups-tlse.fr/4696/},
	abstract = {La quantification des incertitudes lors d'une étude de sûreté peut être réalisée en modélisant les paramètres d'entrée du système physique par des variables aléatoires. Afin de propager les incertitudes affectant les entrées, un modèle de simulation numérique reproduisant la physique du système est exécuté avec différentes combinaisons des paramètres d'entrée, générées suivant leur loi de probabilité jointe. Il est alors possible d'étudier la variabilité de la sortie du code, ou d'estimer certaines quantités d'intérêt spécifiques. Le code étant considéré comme une boîte noire déterministe, la quantité d'intérêt dépend uniquement du choix de la loi de probabilité des entrées. Toutefois, cette distribution de probabilité est elle-même incertaine. En général, elle est choisie grâce aux avis d'experts, qui sont subjectifs et parfois contradictoires, mais aussi grâce à des données expérimentales souvent en nombre insuffisant et entachées d'erreurs. Cette variabilité dans le choix de la distribution se propage jusqu'à la quantité d'intérêt. Cette thèse traite de la prise en compte de cette incertitude dite de deuxième niveau. L'approche proposée, connue sous le nom d'Optimal Uncertainty Quantification ({OUQ}) consiste à évaluer des bornes sur la quantité d'intérêt. De ce fait on ne considère plus une distribution fixée, mais un ensemble de mesures de probabilité sous contraintes de moments sur lequel la quantité d'intérêt est optimisée. Après avoir exposé des résultats théoriques visant à réduire l'optimisation de la quantité d'intérêt aux point extrémaux de l'espace de mesures de probabilité, nous présentons différentes quantités d'intérêt vérifiant les hypothèses du problème. Cette thèse illustre l'ensemble de la méthodologie sur plusieurs cas d'applications, l'un d'eux étant un cas réel étudiant l'évolution de la température de gaine du combustible nucléaire en cas de perte du réfrigérant.},
	institution = {Université de Toulouse, Université Toulouse {III} - Paul Sabatier},
	type = {phdthesis},
	author = {Stenger, Jérôme},
	urldate = {2025-03-13},
	date = {2020-10-02},
	langid = {english},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/2SV33XSK/Stenger - 2020 - Optimal uncertainty quantification of a risk measurement from a computer code.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/VIJP2I9K/4696.html:text/html},
}

@misc{lartaud_sequential_2025,
	title = {Sequential design for surrogate modeling in Bayesian inverse problems},
	url = {http://arxiv.org/abs/2402.16520},
	doi = {10.48550/arXiv.2402.16520},
	abstract = {Sequential design is a highly active field of research in active learning which provides a general framework for designing computer experiments with limited computational budgets. It aims to create efficient surrogate models to replace complex computer codes. Some sequential design strategies can be understood within the Stepwise Uncertainty Reduction ({SUR}) framework. In the {SUR} framework, each new design point is chosen by minimizing the expectation of a metric of uncertainty with respect to the yet unknown new data point. These methods offer an accessible framework for sequential experiment design, including almost sure convergence for common uncertainty functionals. This paper introduces two strategies. The first one, entitled Constraint Set Query ({CSQ}) is adapted from D-optimal designs where the search space is constrained in a ball for the Mahalanobis distance around the maximum a posteriori. The second, known as the {IP}-{SUR} (Inverse Problem {SUR}) strategy, uses a weighted-integrated mean squared prediction error as the uncertainty metric and is derived from {SUR} methods. It is tractable for Gaussian process surrogates with continuous sample paths. It comes with a theoretical guarantee for the almost sure convergence of the uncertainty functional. The premises of this work are highlighted in various test cases, in which these two strategies are compared to other sequential designs.},
	number = {{arXiv}:2402.16520},
	publisher = {{arXiv}},
	author = {Lartaud, Paul and Humbert, Philippe and Garnier, Josselin},
	urldate = {2025-03-13},
	date = {2025-01-02},
	eprinttype = {arxiv},
	eprint = {2402.16520 [stat]},
	keywords = {Statistics - Methodology},
	annotation = {Comment: 22 pages, 12 figures, 2 appendices},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/9WU8A76B/Lartaud et al. - 2025 - Sequential design for surrogate modeling in Bayesian inverse problems.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/HYUK6ACV/2402.html:text/html},
}

@inproceedings{poczos_estimation_2011,
	title = {On the Estimation of \${\textbackslash}alpha\$-Divergences},
	url = {https://proceedings.mlr.press/v15/poczos11a.html},
	abstract = {We propose new nonparametric, consistent Rényi-𝛼α{\textbackslash}alpha and Tsallis-𝛼α{\textbackslash}alpha divergence estimators for continuous distributions. Given two independent and identically distributed samples, a ‘brute force’ approach would be simply to estimate the underlying densities, and plug these densities into the corresponding formulas. However, it is not our goal to consistently estimate these possibly high dimensional densities, and our algorithm avoids estimating them. We will use simple 𝑘kk-nearest-neighbor statistics, and interestingly enough, we will still be able to prove that the proposed divergence estimators are consistent under certain conditions. We will also show how to use them for mutual information estimation, and demonstrate their efficiency by some numerical experiments.},
	eventtitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	pages = {609--617},
	booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	publisher = {{JMLR} Workshop and Conference Proceedings},
	author = {Poczos, Barnabas and Schneider, Jeff},
	urldate = {2025-03-13},
	date = {2011-06-14},
	langid = {english},
	note = {{ISSN}: 1938-7228},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/KV9CTYD7/Poczos et Schneider - 2011 - On the Estimation of \$alpha\$-Divergences.pdf:application/pdf},
}

@inproceedings{atamna_linearly_2017,
	location = {New York, {NY}, {USA}},
	title = {Linearly Convergent Evolution Strategies via Augmented Lagrangian Constraint Handling},
	isbn = {978-1-4503-4651-1},
	url = {https://doi.org/10.1145/3040718.3040732},
	doi = {10.1145/3040718.3040732},
	series = {{FOGA} '17},
	abstract = {We analyze linear convergence of an evolution strategy for constrained optimization with an augmented Lagrangian constraint handling approach. We study the case of multiple active linear constraints and use a Markov chain approach---used to analyze randomized optimization algorithms in the unconstrained case---to establish linear convergence under sufficient conditions. More specifically, we exhibit a class of functions on which a homogeneous Markov chain (defined from the state variables of the algorithm) exists and whose stability implies linear convergence. This class of functions is defined such that the augmented Lagrangian, centered in its value at the optimum and the associated Lagrange multipliers, is positive homogeneous of degree \$2\$, and includes convex quadratic functions. Simulations of the Markov chain are conducted on linearly constrained sphere and ellipsoid functions to validate numerically the stability of the constructed Markov chain.},
	pages = {149--161},
	booktitle = {Proceedings of the 14th {ACM}/{SIGEVO} Conference on Foundations of Genetic Algorithms},
	publisher = {Association for Computing Machinery},
	author = {Atamna, Asma and Auger, Anne and Hansen, Nikolaus},
	urldate = {2025-03-13},
	date = {2017-01-12},
	file = {Version soumise:/Users/antoinevanbiesbroeck/Zotero/storage/8FPW5VT5/Atamna et al. - 2017 - Linearly Convergent Evolution Strategies via Augmented Lagrangian Constraint Handling.pdf:application/pdf},
}

@inproceedings{sypherd_being_2022,
	title = {Being Properly Improper},
	url = {https://proceedings.mlr.press/v162/sypherd22a.html},
	abstract = {Properness for supervised losses stipulates that the loss function shapes the learning algorithm towards the true posterior of the data generating distribution. Unfortunately, data in modern machine learning can be corrupted or twisted in many ways. Hence, optimizing a proper loss function on twisted data could perilously lead the learning algorithm towards the twisted posterior, rather than to the desired clean posterior. Many papers cope with specific twists (e.g., label/feature/adversarial noise), but there is a growing need for a unified and actionable understanding atop properness. Our chief theoretical contribution is a generalization of the properness framework with a notion called twist-properness, which delineates loss functions with the ability to "untwist" the twisted posterior into the clean posterior. Notably, we show that a nontrivial extension of a loss function called alpha-loss, which was first introduced in information theory, is twist-proper. We study the twist-proper alpha-loss under a novel boosting algorithm, called {PILBoost}, and provide formal and experimental results for this algorithm. Our overarching practical conclusion is that the twist-proper alpha-loss outperforms the proper log-loss on several variants of twisted data.},
	eventtitle = {International Conference on Machine Learning},
	pages = {20891--20932},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Sypherd, Tyler and Nock, Richard and Sankar, Lalitha},
	urldate = {2025-03-13},
	date = {2022-06-28},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/WD8CVQSR/Sypherd et al. - 2022 - Being Properly Improper.pdf:application/pdf},
}

@misc{daudel_monotonic_2023,
	title = {Monotonic Alpha-divergence Minimisation for Variational Inference},
	url = {http://arxiv.org/abs/2103.05684},
	doi = {10.48550/arXiv.2103.05684},
	abstract = {In this paper, we introduce a novel family of iterative algorithms which carry out \${\textbackslash}alpha\$-divergence minimisation in a Variational Inference context. They do so by ensuring a systematic decrease at each step in the \${\textbackslash}alpha\$-divergence between the variational and the posterior distributions. In its most general form, the variational distribution is a mixture model and our framework allows us to simultaneously optimise the weights and components parameters of this mixture model. Our approach permits us to build on various methods previously proposed for \${\textbackslash}alpha\$-divergence minimisation such as Gradient or Power Descent schemes and we also shed a new light on an integrated Expectation Maximization algorithm. Lastly, we provide empirical evidence that our methodology yields improved results on several multimodal target distributions and on a real data example.},
	number = {{arXiv}:2103.05684},
	publisher = {{arXiv}},
	author = {Daudel, Kamélia and Douc, Randal and Roueff, François},
	urldate = {2025-03-13},
	date = {2023-04-10},
	eprinttype = {arxiv},
	eprint = {2103.05684 [stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Computation, Statistics - Statistics Theory},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/N48WI2DK/Daudel et al. - 2023 - Monotonic Alpha-divergence Minimisation for Variational Inference.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/584I23YG/2103.html:text/html},
}

@article{jewson_principles_2018,
	title = {Principles of Bayesian Inference Using General Divergence Criteria},
	volume = {20},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/20/6/442},
	doi = {10.3390/e20060442},
	abstract = {When it is acknowledged that all candidate parameterised statistical models are misspecified relative to the data generating process, the decision maker ({DM}) must currently concern themselves with inference for the parameter value minimising the Kullback–Leibler ({KL})-divergence between the model and this process (Walker, 2013). However, it has long been known that minimising the {KL}-divergence places a large weight on correctly capturing the tails of the sample distribution. As a result, the {DM} is required to worry about the robustness of their model to tail misspecifications if they want to conduct principled inference. In this paper we alleviate these concerns for the {DM}. We advance recent methodological developments in general Bayesian updating (Bissiri, Holmes \& Walker, 2016) to propose a statistically well principled Bayesian updating of beliefs targeting the minimisation of more general divergence criteria. We improve both the motivation and the statistical foundations of existing Bayesian minimum divergence estimation (Hooker \& Vidyashankar, 2014; Ghosh \& Basu, 2016), allowing the well principled Bayesian to target predictions from the model that are close to the genuine model in terms of some alternative divergence measure to the {KL}-divergence. Our principled formulation allows us to consider a broader range of divergences than have previously been considered. In fact, we argue defining the divergence measure forms an important, subjective part of any statistical analysis, and aim to provide some decision theoretic rational for this selection. We illustrate how targeting alternative divergence measures can impact the conclusions of simple inference tasks, and discuss then how our methods might apply to more complicated, high dimensional models.},
	pages = {442},
	number = {6},
	journaltitle = {Entropy},
	author = {Jewson, Jack and Smith, Jim Q. and Holmes, Chris},
	urldate = {2025-03-13},
	date = {2018-06},
	langid = {english},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {\textit{M}-open inference, Bayesian updating, Kullback–Leibler divergence, minimum divergence estimation, robustness},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/XWU6MJWS/Jewson et al. - 2018 - Principles of Bayesian Inference Using General Divergence Criteria.pdf:application/pdf},
}

@inproceedings{hernandez-lobato_black-box_2016,
	title = {Black-Box Alpha Divergence Minimization},
	url = {https://proceedings.mlr.press/v48/hernandez-lobatob16.html},
	abstract = {Black-box alpha ({BB}-α) is a new approximate inference method based on the minimization of α-divergences. {BB}-αscales to large datasets because it can be implemented using stochastic gradient descent. {BB}-αcan be applied to complex probabilistic models with little effort since it only requires as input the likelihood function and its gradients. These gradients can be easily obtained using automatic differentiation. By changing the divergence parameter α, the method is able to interpolate between variational Bayes ({VB}) (α→0) and an algorithm similar to expectation propagation ({EP}) (α= 1). Experiments on probit regression and neural network regression and classification problems show that {BB}-αwith non-standard settings of α, such as α= 0.5, usually produces better predictions than with α→0 ({VB}) or α= 1 ({EP}).},
	eventtitle = {International Conference on Machine Learning},
	pages = {1511--1520},
	booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Hernandez-Lobato, Jose and Li, Yingzhen and Rowland, Mark and Bui, Thang and Hernandez-Lobato, Daniel and Turner, Richard},
	urldate = {2025-03-13},
	date = {2016-06-11},
	langid = {english},
	note = {{ISSN}: 1938-7228},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/7GQ577EK/Hernandez-Lobato et al. - 2016 - Black-Box Alpha Divergence Minimization.pdf:application/pdf},
}

@article{rodriguez-santana_adversarial_2022,
	title = {Adversarial α{\textless}math{\textgreater}{\textless}mrow is="true"{\textgreater}{\textless}mi is="true"{\textgreater}α{\textless}/mi{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater}-divergence minimization for Bayesian approximate inference},
	volume = {471},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231220316143},
	doi = {10.1016/j.neucom.2020.09.076},
	abstract = {Neural networks are state-of-the-art models for machine learning problems. They are often trained via back-propagation to find a value of the weights that correctly predicts the observed data. Back-propagation has shown good performance in many applications, however, it cannot easily output an estimate of the uncertainty in the predictions made. Estimating this uncertainty is a critical aspect with important applications. One method to obtain this information consists in following a Bayesian approach to obtain a posterior distribution of the model parameters. This posterior distribution summarizes which parameter values are compatible with the observed data. However, the posterior is often intractable and has to be approximated. Several methods have been devised for this task. Here, we propose a general method for approximate Bayesian inference that is based on minimizing α-divergences, and that allows for flexible approximate distributions. We call this method adversarial α-divergence minimization ({AADM}). We have evaluated {AADM} in the context of Bayesian neural networks. Extensive experiments show that it may lead to better results in terms of the test log-likelihood, and sometimes in terms of the squared error, in regression problems. In classification problems, however, {AADM} gives competitive results.},
	pages = {260--274},
	journaltitle = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Rodríguez-Santana, Simón and Hernández-Lobato, Daniel},
	urldate = {2025-03-13},
	date = {2022-01-30},
	keywords = {Adversarial variational Bayes, Alpha divergences, Approximate inference, Bayesian neural networks},
	file = {Version acceptée:/Users/antoinevanbiesbroeck/Zotero/storage/HQVQMIYP/Rodríguez-Santana et Hernández-Lobato - 2022 - Adversarial αα-divergence minimization for Ba.pdf:application/pdf},
}

@online{noauthor_objective_nodate,
	title = {Objective Bayesian Inference},
	url = {https://www.worldscientific.com/worldscibooks/10.1142/13640},
	abstract = {Bayesian analysis is today understood to be an extremely powerful method of statistical analysis, as well an approach to statistics that is particularly transparent and intuitive. It is thus being ...},
	urldate = {2025-03-13},
	langid = {english},
}

@misc{grenioux_sampling_2024,
	title = {On Sampling with Approximate Transport Maps},
	url = {http://arxiv.org/abs/2302.04763},
	doi = {10.48550/arXiv.2302.04763},
	abstract = {Transport maps can ease the sampling of distributions with non-trivial geometries by transforming them into distributions that are easier to handle. The potential of this approach has risen with the development of Normalizing Flows ({NF}) which are maps parameterized with deep neural networks trained to push a reference distribution towards a target. {NF}-enhanced samplers recently proposed blend (Markov chain) Monte Carlo methods with either (i) proposal draws from the flow or (ii) a flow-based reparametrization. In both cases, the quality of the learned transport conditions performance. The present work clarifies for the first time the relative strengths and weaknesses of these two approaches. Our study concludes that multimodal targets can be reliably handled with flow-based proposals up to moderately high dimensions. In contrast, methods relying on reparametrization struggle with multimodality but are more robust otherwise in high-dimensional settings and under poor training. To further illustrate the influence of target-proposal adequacy, we also derive a new quantitative bound for the mixing time of the Independent Metropolis-Hastings sampler.},
	number = {{arXiv}:2302.04763},
	publisher = {{arXiv}},
	author = {Grenioux, Louis and Durmus, Alain and Moulines, Éric and Gabrié, Marylou},
	urldate = {2025-03-13},
	date = {2024-02-18},
	eprinttype = {arxiv},
	eprint = {2302.04763 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/34KL4WQZ/Grenioux et al. - 2024 - On Sampling with Approximate Transport Maps.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/5NSUDZ87/2302.html:text/html},
}

@inproceedings{magdon-ismail_neural_1998,
	title = {Neural Networks for Density Estimation},
	volume = {11},
	url = {https://papers.nips.cc/paper_files/paper/1998/hash/9327969053c0068dd9e07c529866b94d-Abstract.html},
	abstract = {We  introduce two  new  techniques for  density estimation.  Our ap(cid:173) proach poses the problem as  a  supervised learning task which  can  be  performed  using  Neural  Networks.  We  introduce  a  stochas(cid:173) tic method for  learning the cumulative distribution  and an  analo(cid:173) gous  deterministic technique.  We  demonstrate convergence of our  methods  both theoretically and experimentally, and provide com(cid:173) parisons with the Parzen estimate.  Our theoretical results demon(cid:173) strate better convergence properties than the Parzen estimate.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {{MIT} Press},
	author = {Magdon-Ismail, Malik and Atiya, Amir},
	urldate = {2025-03-13},
	date = {1998},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/G63D5DUU/Magdon-Ismail et Atiya - 1998 - Neural Networks for Density Estimation.pdf:application/pdf},
}

@article{liu_density_2021,
	title = {Density estimation using deep generative neural networks},
	volume = {118},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.2101344118},
	doi = {10.1073/pnas.2101344118},
	abstract = {Density estimation is one of the fundamental problems in both statistics and machine learning. In this study, we propose Roundtrip, a computational framework for general-purpose density estimation based on deep generative neural networks. Roundtrip retains the generative power of deep generative models, such as generative adversarial networks ({GANs}) while it also provides estimates of density values, thus supporting both data generation and density estimation. Unlike previous neural density estimators that put stringent conditions on the transformation from the latent space to the data space, Roundtrip enables the use of much more general mappings where target density is modeled by learning a manifold induced from a base density (e.g., Gaussian distribution). Roundtrip provides a statistical framework for {GAN} models where an explicit evaluation of density values is feasible. In numerical experiments, Roundtrip exceeds state-of-the-art performance in a diverse range of density estimation tasks.},
	pages = {e2101344118},
	number = {15},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Liu, Qiao and Xu, Jiaze and Jiang, Rui and Wong, Wing Hung},
	urldate = {2025-03-13},
	date = {2021-04-13},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/GAWXQZKX/Liu et al. - 2021 - Density estimation using deep generative neural networks.pdf:application/pdf},
}

@misc{rezende_variational_2016,
	title = {Variational Inference with Normalizing Flows},
	url = {http://arxiv.org/abs/1505.05770},
	doi = {10.48550/arXiv.1505.05770},
	abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
	number = {{arXiv}:1505.05770},
	publisher = {{arXiv}},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
	urldate = {2025-03-13},
	date = {2016-06-14},
	eprinttype = {arxiv},
	eprint = {1505.05770 [stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
	annotation = {Comment: Proceedings of the 32nd International Conference on Machine Learning},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/8MAF7GGE/Rezende et Mohamed - 2016 - Variational Inference with Normalizing Flows.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/NHSKM2TZ/1505.html:text/html},
}

@misc{allouche_learning_2023,
	title = {Learning out-of-sample Expected Shortfall and Conditional Tail Moments with neural networks. Application to cryptocurrency data},
	url = {https://inria.hal.science/hal-04347859},
	abstract = {We propose new parameterizations for neural networks in order to estimate out-of-sample Expected Shortfall, and even more generally, out-of-sample conditional tail moments, in heavy-tailed settings as functions of confidence levels. The proposed neural network estimator is able to extrapolate in the distribution tails thanks to an extension of the usual extreme-value second-order condition to an arbitrary order. The convergence rate of the uniform error between the log-conditional tail moment and its neural network approximation is established. The finite sample performance of the neural network estimator is compared to bias-reduced extreme-value competitors on simulated data. It is shown that our method outperforms them in difficult heavy-tailed situations where other estimators almost all fail. Finally, the neural network estimator is tested on real data to investigate the behavior of cryptocurrency extreme loss returns.},
	author = {Allouche, Michaël and Girard, Stéphane and Gobet, Emmanuel},
	urldate = {2025-03-13},
	date = {2023},
	langid = {english},
	note = {Pages: 545},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/AWYEK34Q/Allouche et al. - 2023 - Learning out-of-sample Expected Shortfall and Conditional Tail Moments with neural networks. Applica.pdf:application/pdf},
}

@article{allouche_estimation_2023,
	title = {Estimation of extreme quantiles from heavy-tailed distributions with neural networks},
	volume = {34},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-023-10331-2},
	doi = {10.1007/s11222-023-10331-2},
	abstract = {We propose new parametrizations for neural networks in order to estimate extreme quantiles in both non-conditional and conditional heavy-tailed settings. All proposed neural network estimators feature a bias correction based on an extension of the usual second-order condition to an arbitrary order. The convergence rate of the uniform error between extreme log-quantiles and their neural network approximation is established. The finite sample performances of the non-conditional neural network estimator are compared to other bias-reduced extreme-value competitors on simulated data. It is shown that our method outperforms them in difficult heavy-tailed situations where other estimators almost all fail. Finally, the conditional neural network estimators are implemented to investigate the behavior of extreme rainfalls as functions of their geographical location in the southern part of France. The source code is available at https://github.com/michael-allouche/nn-quantile-extrapolation.git.},
	pages = {12},
	number = {1},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Allouche, Michaël and Girard, Stéphane and Gobet, Emmanuel},
	urldate = {2025-03-13},
	date = {2023-10-28},
	langid = {english},
	keywords = {60G70, 62G32, 68T07, Conditional quantile estimation, Extreme-value theory, Heavy-tailed distribution, Neural networks, Quantile estimation},
}

@misc{allouche_simulation_2024,
	title = {On the simulation of extreme events with neural networks},
	url = {https://inria.hal.science/hal-04416809},
	abstract = {This article aims at investigating the use of generative methods based on neural networks to simulate extreme events. Although very popular, these methods are mainly invoked in empirical works. Therefore, providing theoretical guidelines for using such models in extreme values context is of primal importance. To this end, we propose an overview of most recent generative methods dedicated to extremes, giving some theoretical and practical tips on their tail behaviour thanks to both extreme-value and copula tools.},
	author = {Allouche, Michaël and Girard, Stéphane and Gobet, Emmanuel},
	urldate = {2025-03-13},
	date = {2024-01-25},
	langid = {english},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/I4ETYQVH/Allouche et al. - 2024 - On the simulation of extreme events with neural networks.pdf:application/pdf},
}

@misc{shen_variational_2024,
	title = {Variational Learning is Effective for Large Deep Networks},
	url = {http://arxiv.org/abs/2402.17641},
	doi = {10.48550/arXiv.2402.17641},
	abstract = {We give extensive empirical evidence against the common belief that variational learning is ineffective for large neural networks. We show that an optimizer called Improved Variational Online Newton ({IVON}) consistently matches or outperforms Adam for training large networks such as {GPT}-2 and {ResNets} from scratch. {IVON}'s computational costs are nearly identical to Adam but its predictive uncertainty is better. We show several new use cases of {IVON} where we improve finetuning and model merging in Large Language Models, accurately predict generalization error, and faithfully estimate sensitivity to data. We find overwhelming evidence that variational learning is effective.},
	number = {{arXiv}:2402.17641},
	publisher = {{arXiv}},
	author = {Shen, Yuesong and Daheim, Nico and Cong, Bai and Nickl, Peter and Marconi, Gian Maria and Bazan, Clement and Yokota, Rio and Gurevych, Iryna and Cremers, Daniel and Khan, Mohammad Emtiyaz and Möllenhoff, Thomas},
	urldate = {2025-03-13},
	date = {2024-06-06},
	eprinttype = {arxiv},
	eprint = {2402.17641 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
	annotation = {Comment: Published at International Conference on Machine Learning ({ICML}), 2024. The first two authors contributed equally. Code is available here: https://github.com/team-approx-bayes/ivon},
	file = {Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/EQWJXQU8/Shen et al. - 2024 - Variational Learning is Effective for Large Deep Networks.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/NWJPJS2J/2402.html:text/html},
}

@article{hashimoto_reference_2021,
	title = {Reference priors via α{\textless}math{\textgreater}{\textless}mi is="true"{\textgreater}α{\textless}/mi{\textgreater}{\textless}/math{\textgreater}-divergence for a certain non-regular model in the presence of a nuisance parameter},
	volume = {213},
	issn = {0378-3758},
	url = {https://www.sciencedirect.com/science/article/pii/S0378375820301221},
	doi = {10.1016/j.jspi.2020.11.007},
	abstract = {This paper presents reference priors for non-regular model whose support depends on an unknown parameter. A multi-parameter family which includes both regular and non-regular structures is considered. The resulting priors are obtained by asymptotically maximizing the expected α-divergence between the prior and the corresponding posterior distribution. Some examples of reference priors for typical multi-parameter non-regular distributions such as the location-scale family of distributions and the truncated Weibull distribution are also given.},
	pages = {162--178},
	journaltitle = {Journal of Statistical Planning and Inference},
	shortjournal = {Journal of Statistical Planning and Inference},
	author = {Hashimoto, Shintaro},
	urldate = {2025-03-13},
	date = {2021-07-01},
	keywords = {-divergence, Bayesian inference, Location-scale model, Non-regular, Reference priors},
}

@book{vovk_algorithmic_2022,
	location = {Cham},
	title = {Algorithmic Learning in a Random World},
	rights = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-06648-1 978-3-031-06649-8},
	url = {https://link.springer.com/10.1007/978-3-031-06649-8},
	publisher = {Springer International Publishing},
	author = {Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
	urldate = {2025-03-21},
	date = {2022},
	langid = {english},
	doi = {10.1007/978-3-031-06649-8},
	keywords = {Conformal prediction, conformal predictive distributions, conformal testing, machine learning, nonparametric statistics, online compression modeling, Venn prediction},
	file = {PDF:/Users/antoinevanbiesbroeck/Zotero/storage/8P9HSMS3/Vovk et al. - 2022 - Algorithmic Learning in a Random World.pdf:application/pdf},
}

@article{wasserman_frasian_2011,
	title = {Frasian Inference},
	volume = {26},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/journals/statistical-science/volume-26/issue-3/Frasian-Inference/10.1214/11-STS352C.full},
	doi = {10.1214/11-STS352C},
	abstract = {Don Fraser has given an interesting account of the agreements and disagreements between Bayesian posterior probabilities and confidence levels. In this comment I discuss some cases where the lack of such agreement is extreme. I then discuss a few cases where it is possible to have Bayes procedures with frequentist validity. Such frequentist-Bayesian—or Frasian—methods deserve more attention.},
	pages = {322--325},
	number = {3},
	journaltitle = {Statistical Science},
	author = {Wasserman, Larry},
	urldate = {2025-03-21},
	date = {2011-08},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Statistics - Methodology},
	annotation = {Comment: Published in at http://dx.doi.org/10.1214/11-{STS}352C the Statistical Science (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/29C7PPT5/Wasserman - 2011 - Frasian Inference.pdf:application/pdf;Preprint PDF:/Users/antoinevanbiesbroeck/Zotero/storage/PT6M7UZJ/Wasserman - 2011 - Frasian Inference.pdf:application/pdf;Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/I78MX9KE/1202.html:text/html},
}

@inproceedings{fong_conformal_2021,
	title = {Conformal Bayesian Computation},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/97785e0500ad16c18574c64189ccf4b4-Abstract.html},
	pages = {18268--18279},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Fong, Edwin and Holmes, Chris C},
	urldate = {2025-03-21},
	date = {2021},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/H9XZ8EZI/Fong et Holmes - 2021 - Conformal Bayesian Computation.pdf:application/pdf},
}

@book{vovk_algorithmic_2005,
	location = {New York},
	edition = {1},
	title = {Algorithmic Learning in a Random World},
	rights = {http://www.springer.com/tdm},
	isbn = {978-0-387-00152-4},
	url = {http://link.springer.com/10.1007/b106715},
	publisher = {Springer-Verlag},
	author = {Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
	urldate = {2025-03-21},
	date = {2005},
	langid = {english},
	doi = {10.1007/b106715},
	keywords = {algorithms, Approximation, classification, Conformal prediction, learning, machine learning, modeling, Randomness, Regression},
	annotation = {doi: 10.1007/b106715
},
}

@thesis{roger_seisme_2020,
	title = {Le séisme, la centrale et la règle : instaurer et maintenir la robustesse des installations nucléaires en France},
	url = {https://theses.hal.science/tel-03414838},
	shorttitle = {Le séisme, la centrale et la règle},
	abstract = {Cette thèse prend comme point de départ l'étonnement de voir les centrales nucléaires tenir sur la durée. En effet, malgré le vieillissement des installations, malgré l'obsolescence de certains équipements, malgré l'immense évolution des connaissances scientifiques et techniques depuis l'époque où ces technologies ont été développées, malgré des accidents qui ont remis en cause la capacité de prévenir totalement les risques, les centrales nucléaires françaises sont encore débout, encore en fonctionnement et, en 2020, il est plus que jamais question d'étendre leur durée de vie au-delà de leur limite initiale. Ce parcours de vie d'ouvrages industriels dangereux, qui s'étend sur 70 ans, incite à poser la question des risques technologiques sur une temporalité longue et à examiner comment la sécurité de ces installations a pu être construite puis maintenue de sorte à pouvoir fonctionner aussi longtemps. Cette thèse propose d'aborder ce sujet en étudiant l'histoire de la robustesse des installations nucléaires françaises face à la menace sismique. Par une sociologie embarquée et grâce à un accès privilégié aux archives de la sûreté nucléaire en France, ce travail propose une plongée dans le monde des experts, scientifiques et ingénieurs, qui oeuvrent depuis 60 ans pour instaurer la robustesse des installations nucléaires en France. Cette instauration se décompose en quatre épisodes qui structurent l'analyse : l'élaboration de la robustesse autour du site nucléaire de Fessenheim, la réalisation de la robustesse à l'échelle industrielle à partir du cas du site de Tricastin, la maintenance de la robustesse face à l'évolution des connaissances et enfin la réparation de la robustesse après l'accident de Fukushima Daiichi. Ce que met en exergue ce travail c'est que la robustesse, loin d'être une donnée objectivable, intrinsèque aux objets, est en réalité une qualité subjective fondée sur une conviction partagée au sein d'une arène spécifique. Dans notre cas, cette conviction est entièrement fondée sur une série de conventions d'équivalence (Desrosieres, 1993) qui lie entre eux différents modes d'existence du risque : comme sujet politique, comme objet scientifique et comme propriété d'un objet technique. La robustesse dépend alors de la pérennité de ces conventions d'équivalence et le travail des experts peut alors être vu comme celui de mainteneur de leur validité. En étudiant l'élaboration et le maintien de la conviction dans le caractère robuste des installations nucléaires, ce travail invite à poser un regard nouveau sur les risques en étant attentif à la fois à leur histoire et à leurs multiples modes d'existence.},
	institution = {Université Paris Cité},
	type = {phdthesis},
	author = {Roger, Mathias},
	urldate = {2025-03-26},
	date = {2020-12-14},
	langid = {french},
	file = {Full Text PDF:/Users/antoinevanbiesbroeck/Zotero/storage/A4Z4CI28/Roger - 2020 - Le séisme, la centrale et la règle  instaurer et maintenir la robustesse des installations nucléair.pdf:application/pdf},
}

@report{nrc_pra_1983,
	title = {{PRA} Procedures Guide: A Guide to the Performance of Probabilistic Risk Assessments for Nuclear Power Plants},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr2300/vol1/index.html},
	shorttitle = {{PRA} Procedures Guide},
	abstract = {{PRA}  Procedures Guide: A Guide to the Performance of Probabilistic Risk Assessments for Nuclear Powe},
	number = {{NUREG}/{CR}-2300},
	institution = {Nuclear Regulatory Commission},
	author = {{NRC}},
	urldate = {2025-04-03},
	date = {1983},
	langid = {american},
	file = {Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/G8JT5L3E/index.html:text/html},
}

@article{cornell_engineering_1968,
	title = {Engineering seismic risk analysis},
	volume = {58},
	issn = {0037-1106},
	url = {https://doi.org/10.1785/BSSA0580051583},
	doi = {10.1785/BSSA0580051583},
	abstract = {This paper introduces a method for the evaluation of the seismic risk at the site of an engineering project. The results are in terms of a ground motion parameter (such as peak acceleration) versus average return period. The method incorporates the influence of all potential sources of earthquakes and the average activity rates assigned to them. Arbitrary geographical relationships between the site and potential point, line, or areal sources can be modeled with computational ease. In the range of interest, the derived distributions of maximum annual ground motions are in the form of Type I or Type {II} extreme value distributions, if the more commonly assumed magnitude distribution and attenuation laws are used.},
	pages = {1583--1606},
	number = {5},
	journaltitle = {Bulletin of the Seismological Society of America},
	shortjournal = {Bulletin of the Seismological Society of America},
	author = {Cornell, C. Allin},
	urldate = {2025-04-03},
	date = {1968-10-01},
	file = {Snapshot:/Users/antoinevanbiesbroeck/Zotero/storage/IV5CXXXQ/Engineering-seismic-risk-analysis.html:text/html},
}

@mvbook{iaea_fukushima_2015,
	location = {Vienna (Austria)},
	title = {The Fukushima Daiichi Accident. Technical Volume 2/5. Safety Assessment},
	volume = {2},
	isbn = {978-92-0-107015-9},
	volumes = {5},
	pagetotal = {186},
	publisher = {International Atomic Energy Agency},
	author = {{IAEA}},
	date = {2015-08},
}

@report{asn_regle_2002,
	title = {Règle Fondamentale de Sûreté : Développement et utilisation des études probabilistes de sûreté},
	url = {https://www.asn.fr/reglementation/rfs/rfs-relatives-aux-rep/rfs-2002-1-du-26-12-2002},
	number = {{RFS} 2002-01},
	institution = {Autorité de sûreté nucléaire},
	author = {{ASN}},
	date = {2002},
	langid = {french},
}

@inproceedings{gauchy_inference_2023-1,
	title = {Inférence variationelle de lois a priori de référence},
	booktitle = {Proceedings des 54èmes Journées de Statistiques de la {SFDS} ({JdS})},
	author = {Gauchy, Clément and Van Biesbroeck, Antoine and Feau, Cyril and Garnier, Josselin},
	date = {2023},
	note = {Place: Brussels, Belgium},
}

@article{bousquet_reference_2010,
	title = {Reference priors of nuisance parameters in Bayesian sequential population analysis},
	doi = {10.48550/arXiv.1007.5388},
	journaltitle = {{arXiv}.1007.5388},
	author = {Bousquet, Nicolas},
	date = {2010},
}

@incollection{iooss_review_2015,
	location = {Boston, {MA}},
	title = {A Review on Global Sensitivity Analysis Methods},
	isbn = {978-1-4899-7547-8},
	pages = {101--122},
	booktitle = {Uncertainty Management in Simulation-Optimization of Complex Systems: Algorithms and Applications},
	publisher = {Springer {US}},
	author = {Iooss, Bertrand and Lemaître, Paul},
	editor = {Dellino, Gabriella and Meloni, Carlo},
	date = {2015},
	doi = {10.1007/978-1-4899-7547-8_5},
}

@article{hickling_flexible_2024,
	title = {Flexible Tails for Normalizing Flows},
	doi = {10.48550/arXiv.2406.16971},
	journaltitle = {{arXiv}.2406.16971},
	author = {Hickling, Tennessee and Prangle, Dennis},
	date = {2024},
}

@inproceedings{goodfellow_generative_2014,
	title = {Generative Adversarial Nets},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	date = {2014},
}

@article{arbel_bayes_2023,
	title = {Bayes in action in deep learning and dictionary learning},
	volume = {74},
	doi = {10.1051/proc/202374090},
	pages = {90--107},
	journaltitle = {{ESAIM}: {ProcS}},
	author = {Arbel, Julyan and Dang, Hong-Phuong and Elvira, Clement and Herzet, Cedric and Naulet, Zacharie and Vladimirova, Mariia},
	date = {2023},
}

@article{del_val_surrogate-based_2022,
	title = {A surrogate-based optimal likelihood function for the Bayesian calibration of catalytic recombination in atmospheric entry protection materials},
	volume = {101},
	doi = {10.1016/j.apm.2021.07.019},
	pages = {791--810},
	journaltitle = {Applied Mathematical Modelling},
	author = {del Val, Anabel and Le Maître, Olivier P. and Magin, Thierry E. and Chazot, Olivier and Congedo, Pietro M.},
	date = {2022},
}

@article{schobi_polynomial-chaos-based_2015,
	title = {{POLYNOMIAL}-{CHAOS}-{BASED} {KRIGING}},
	volume = {5},
	doi = {10.1615/Int.J.UncertaintyQuantification.2015012467},
	pages = {171--193},
	number = {2},
	journaltitle = {International Journal for Uncertainty Quantification},
	author = {Schobi, Roland and Sudret, Bruno and Wiart, Joe},
	date = {2015},
}

@inproceedings{wimmer_quantifying_2023,
	title = {Quantifying aleatoric and epistemic uncertainty in machine learning: Are conditional entropy and mutual information appropriate measures?},
	volume = {216},
	url = {https://proceedings.mlr.press/v216/wimmer23a.html},
	pages = {2282--2292},
	booktitle = {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},
	publisher = {{PMLR}},
	author = {Wimmer, Lisa and Sale, Yusuf and Hofman, Paul and Bischl, Bernd and Hüllermeier, Eyke},
	date = {2023},
}

@article{il_idrissi_quantile-constrained_2024,
	title = {Quantile-constrained Wasserstein projections for robust interpretability of numerical and machine learning models},
	volume = {18},
	doi = {10.1214/24-EJS2268},
	pages = {2721--2770},
	number = {2},
	journaltitle = {Electronic Journal of Statistics},
	author = {Il Idrissi, Marouane and Bousquet, Nicolas and Gamboa, Fabrice and Iooss, Bertrand and Loubes, Jean-Michel},
	date = {2024},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
}

@article{hullermeier_aleatoric_2019,
	title = {Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods},
	volume = {110},
	doi = {10.1007/s10994-021-05946-3},
	pages = {457--506},
	journaltitle = {Machine Learning},
	author = {Hüllermeier, Eyke and Waegeman, Willem},
	date = {2019},
}

@article{de_mathelin_deep_2024,
	title = {Deep Anti-Regularized Ensembles provide reliable out-of-distribution uncertainty quantification},
	url = {https://hal.science/hal-04455937},
	journaltitle = {{arXiv}.2304.04042},
	author = {de Mathelin, Antoine and Deheeger, Francois and Mougeot, Mathilde and Vayatis, Nicolas},
	date = {2024},
}

@article{garnier_sensitivity_2024,
	title = {Sensitivity analysis of colored noise-driven interacting particle systems},
	doi = {10.48550/arXiv.2406.11454},
	journaltitle = {{arXiv}.2406.11454},
	author = {Garnier, Josselin and Ip, Harry and Mertz, Laurent},
	date = {2024},
}

@thesis{bousquet_contributions_2024,
	title = {Contributions to the statistical quantification of uncertainties affecting the use of numerical models},
	url = {https://perso.lpsm.paris/~bousquet/hdr/hdr.pdf},
	institution = {Sorbonne université},
	type = {Habilitation à diriger des recherches},
	author = {Bousquet, Nicolas},
	date = {2024},
}

@article{minini_finite_2023,
	title = {Finite element-based probabilistic framework including Bayesian inference for predicting displacements due to tunnel excavation},
	volume = {162},
	doi = {10.1016/j.compgeo.2023.105604},
	pages = {105604},
	journaltitle = {Computers and Geotechnics},
	author = {Minini, Jocelyn and Zhang, Yi and Groslambert, Marc and Commend, Stéphane},
	date = {2023},
}

@article{jaber_sensitivity_2025,
	title = {{SENSITIVITY} {ANALYSES} {OF} A {MULTIPHYSICS} {LONG}-{TERM} {CLOGGING} {MODEL} {FOR} {STEAM} {GENERATORS}},
	volume = {15},
	doi = {10.1615/Int.J.UncertaintyQuantification.2024051489},
	pages = {27--45},
	number = {1},
	journaltitle = {International Journal for Uncertainty Quantification},
	author = {Jaber, Edgar and Chabridon, Vincent and Remy, Emmanuel and Baudin, Michael and Lucor, Didier and Mougeot, Mathilde and Iooss, Bertrand},
	date = {2025},
}

@inproceedings{ehret_radar_2024,
	title = {Radar Fields: An Extension of Radiance Fields to {SAR}},
	doi = {10.1109/CVPRW63382.2024.00061},
	pages = {564--574},
	booktitle = {{IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	author = {Ehret, Thibaud and Marí, Roger and Derksen, Dawa and Gasnier, Nicolas and Facciolo, Gabriele},
	date = {2024},
}

@inproceedings{dib_bayesian_2021,
	title = {Bayesian Feature Discovery for Predictive Maintenance},
	doi = {10.23919/EUSIPCO54536.2021.9616188},
	pages = {1421--1425},
	booktitle = {29th European Signal Processing Conference ({EUSIPCO})},
	author = {Dib, Amir and Truong, Charles and Oudre, Laurent and Mougeot, Mathilde and Vayatis, Nicolas and Nonne, Heloïse},
	date = {2021},
}

@inproceedings{salmona_can_2022,
	title = {Can Push-forward Generative Models Fit Multimodal Distributions?},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/45f0d179ef7e10eb7366550cd4e574ae-Paper-Conference.pdf},
	pages = {10766--10779},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Salmona, Antoine and De Bortoli, Valentin and Delon, Julie and Desolneux, Agnès},
	date = {2022},
}

@thesis{iooss_contributions_2009,
	title = {Contributions au traitement des incertitudes en modélisation numérique : propagation d'ondes en milieu aléatoire et analyse statistique d'expériences simulées},
	url = {https://theses.hal.science/tel-00360995},
	institution = {Université Paul Sabatier - Toulouse {III}},
	type = {Accreditation to supervise research},
	author = {Iooss, Bertrand},
	date = {2009-01},
	keywords = {experience numerique, incertitude, krigeage, kriging, metamodel, metamodele, milieu aleatoire, numerical experiment, onde, random medium, sensibilite, sensitivity, simulation, statistics, statistique, temps de trajet, traveltime, uncertainty, wave},
}

@thesis{sudret_uncertainty_2007,
	title = {Uncertainty propagation and sensitivity analysis in mechanical models - Contributions to structural reliability and stochastic spectral methods},
	url = {https://ethz.ch/content/dam/ethz/special-interest/baug/ibk/risk-safety-and-uncertainty-dam/publications/reports/HDRSudret.pdf},
	institution = {Université Blaise Pascal - Clermont {II}},
	type = {Accreditation to supervise research},
	author = {Sudret, Bruno},
	date = {2007-10},
}

@article{nguyen_surrogate_2009,
	title = {On surrogate loss functions and f-divergences},
	volume = {37},
	doi = {10.1214/08-AOS595},
	pages = {876--904},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Nguyen, {XuanLong} and Wainwright, Martin J. and Jordan, Michael I.},
	date = {2009},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Ali-Silvey divergences, Bayes consistency, Binary classification, discriminant analysis, f-divergences, nonparametric decentralized detection, quantizer design, statistical machine learning, surrogate losses},
}

@report{minka_divergence_2005,
	title = {Divergence Measures and Message Passing},
	url = {https://www.microsoft.com/en-us/research/publication/divergence-measures-and-message-passing/},
	pages = {17},
	number = {{MSR}-{TR}-2005-173},
	institution = {Microsoft Ltd},
	author = {Minka, Tom},
	date = {2005-01},
}

@article{bach_sum--squares_2023,
	title = {Sum-of-Squares Relaxations for Information Theory and Variational Inference},
	doi = {10.48550/arXiv.2206.13285},
	author = {Bach, Francis},
	date = {2023},
	note = {\_eprint: 2206.13285},
	annotation = {{arXiv}.2206.13285},
}

@article{picard-weibel_change_2022,
	title = {On change of measure inequalities for f-divergences},
	doi = {10.48550/arXiv.2202.05568},
	author = {Picard-Weibel, Antoine and Guedj, Benjamin},
	date = {2022},
	note = {Publisher: {arXiv}},
	annotation = {{arXiv}.2202.05568},
}

@inproceedings{mironov_renyi_2017,
	title = {Rényi Differential Privacy},
	doi = {10.1109/CSF.2017.11},
	pages = {263--275},
	booktitle = {2017 {IEEE} 30th Computer Security Foundations Symposium ({CSF})},
	author = {Mironov, Ilya},
	date = {2017},
}
